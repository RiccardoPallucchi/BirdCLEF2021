{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm.notebook import tqdm, trange\nimport os\nfrom typing import Mapping, Union, Optional, Callable, Dict\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import Dataset, Subset, DataLoader, SubsetRandomSampler, TensorDataset, ConcatDataset\nimport warnings\nwarnings.filterwarnings(action='ignore')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:01.578894Z","iopub.execute_input":"2022-05-15T22:03:01.579187Z","iopub.status.idle":"2022-05-15T22:03:01.586217Z","shell.execute_reply.started":"2022-05-15T22:03:01.579153Z","shell.execute_reply":"2022-05-15T22:03:01.585162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset and data distribution","metadata":{}},{"cell_type":"code","source":"SAMPLING_RATE = 32000 # Hertz\nINPUT_LENGTH = 5      # seconds\nSPEC_SHAPE = (48,128) # spectrogram shape\nFMIN=500              # Hz (~min frequency for birds)\nFMAX=12500            # Hz (~max frequency for birds)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:01.597037Z","iopub.execute_input":"2022-05-15T22:03:01.597357Z","iopub.status.idle":"2022-05-15T22:03:01.602433Z","shell.execute_reply.started":"2022-05-15T22:03:01.597314Z","shell.execute_reply":"2022-05-15T22:03:01.601458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_MEAN = 0.3674\nDATA_STD = 0.1928\n\nMETA_MEAN = [24.472804615395624, -79.96082831218337, 162.2867799090244, 619.9162929032668]\nMETA_STD = [22.10848093451316, 38.37072607349947, 88.93816236402917, 266.60113126777134]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-15T22:03:01.603678Z","iopub.execute_input":"2022-05-15T22:03:01.604487Z","iopub.status.idle":"2022-05-15T22:03:01.612806Z","shell.execute_reply.started":"2022-05-15T22:03:01.604456Z","shell.execute_reply":"2022-05-15T22:03:01.611895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metadata","metadata":{}},{"cell_type":"code","source":"# Load metadata file\nmetadata_df = pd.read_csv('../input/birdclef-2021/train_metadata.csv')\nall_species = metadata_df['primary_label'].unique()\nmeta_df = metadata_df[[\"filename\",\"primary_label\",\"latitude\",\"longitude\",\"date\",\"time\",\"rating\"]]  # retain\n# TIME OF DAY NOT PRESENT ON TEST DATA: USELESS\nmeta_df","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:01.613838Z","iopub.execute_input":"2022-05-15T22:03:01.614074Z","iopub.status.idle":"2022-05-15T22:03:01.933391Z","shell.execute_reply.started":"2022-05-15T22:03:01.614047Z","shell.execute_reply":"2022-05-15T22:03:01.932763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.mode.chained_assignment = None  # default='warn'\n\n# express DATE in days (remove year)\ndef date_transform(date):\n    return int(date.rsplit('-')[2]) + max(0, int(date.rsplit('-')[1])-1)*30\nmeta_df['date'] = meta_df['date'].apply(date_transform)\n\n# express TIME in minutes\ndef time_transform(time):\n   # exclude '?', 'xx', 'xx:xx', 'night', 'am'\n    if not(any(map(str.isdigit, time))):     # if no numbers inside\n        return np.random.randint(0,1440)     # method1: in this way we will not increase a specific time slot\n    else:\n        Q = 0\n        time = time.lower()                  # AM,PM->am,pm\n        if 'pm' in time:\n            Q = 1\n        time = time.replace('pm','')\n        time = time.replace('am','')\n        time = time.rsplit(':')\n        minutes = 0\n        if len(time)>1:\n            minutes = int(time[1])\n        result = (int(time[0]) + Q*12)*60 + minutes\n        return( result%1440 )                # there are also '12:30pm', '12:15pm', '24:15', etc\nmeta_df['time'] = meta_df['time'].apply(time_transform)\nmeta_df","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:01.934746Z","iopub.execute_input":"2022-05-15T22:03:01.93541Z","iopub.status.idle":"2022-05-15T22:03:02.263727Z","shell.execute_reply.started":"2022-05-15T22:03:01.935377Z","shell.execute_reply":"2022-05-15T22:03:02.262943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The model","metadata":{}},{"cell_type":"code","source":"# (ReLU BEFORE AND AFTER ADDITION) +dropout \nclass ResBlock1(nn.Module):\n    def __init__(self, in_channels, out_channels, downsample):\n        super().__init__()\n        if downsample:\n            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),\n                nn.BatchNorm2d(out_channels)\n            )\n        else:\n            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n            self.shortcut = nn.Sequential()\n\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.drop2d = nn.Dropout2d(p=0.1)\n\n    def forward(self, input):\n        shortcut = self.shortcut(input)\n        \n        input = nn.ReLU()(self.bn1(self.conv1(input)))          # pool substituted with stride\n        input = self.drop2d(input)\n        input = nn.ReLU()(self.bn2(self.conv2(input)))\n        input = input + shortcut\n        return nn.ReLU()(input)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ResNet34 first version\nclass ResNet34(nn.Module):\n    def __init__(self, in_channels, resblock, outputs=397):\n        super().__init__()\n        self.layer0 = nn.Sequential(\n            nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU()\n        )\n\n        self.layer1 = nn.Sequential(\n            resblock(64, 64, downsample=False),\n            resblock(64, 64, downsample=False),\n            resblock(64, 64, downsample=False)\n        )\n\n        self.layer2 = nn.Sequential(\n            resblock(64, 128, downsample=True),\n            resblock(128, 128, downsample=False),\n            resblock(128, 128, downsample=False),\n            resblock(128, 128, downsample=False)\n        )\n\n        self.layer3 = nn.Sequential(\n            resblock(128, 256, downsample=True),\n            resblock(256, 256, downsample=False),\n            resblock(256, 256, downsample=False),\n            resblock(256, 256, downsample=False),\n            resblock(256, 256, downsample=False),\n            resblock(256, 256, downsample=False)\n        )\n\n\n        self.layer4 = nn.Sequential(\n            resblock(256, 512, downsample=True),\n            resblock(512, 512, downsample=False),\n            resblock(512, 512, downsample=False),\n        )\n\n        self.meta_rep = 64\n        self.gap = torch.nn.AdaptiveAvgPool2d(1)        \n        self.fc = torch.nn.Linear(512 + self.meta_rep*3, outputs)\n        self.drop = nn.Dropout(p=0.4)\n\n    def forward(self, input):\n        \n        D = input[0]  # data\n        M = input[1]  # meta\n        Lat = M[:,0].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        Lon = M[:,1].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        Date = M[:,2].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        \n        D = self.layer0(D)\n        D = self.layer1(D)\n        D = self.layer2(D)\n        D = self.layer3(D)\n        D = self.layer4(D)\n        D = self.gap(D)                # [64, feature_maps, h, w] -> [64, feature_maps, 1]\n\n        D = D.view(D.shape[0], -1)     # [64, feature_maps, 1]    ->  [64, feature_maps]\n        D = self.drop(D)   \n        DM = torch.cat((D, Lat, Lon, Date),1)    # data & meta\n        \n        DM = self.fc(DM)\n\n        return DM","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResBottleneckBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, downsample):\n        super().__init__()\n        self.downsample = downsample\n        self.conv1 = nn.Conv2d(in_channels, out_channels//4, kernel_size=1, stride=1)\n        self.conv2 = nn.Conv2d(out_channels//4, out_channels//4, kernel_size=3, stride=2 if downsample else 1, padding=1)\n        self.conv3 = nn.Conv2d(out_channels//4, out_channels, kernel_size=1, stride=1)\n        self.shortcut = nn.Sequential()\n        \n        if self.downsample or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2 if self.downsample else 1),\n                nn.BatchNorm2d(out_channels)\n            )\n\n        self.bn1 = nn.BatchNorm2d(out_channels//4)\n        self.bn2 = nn.BatchNorm2d(out_channels//4)\n        self.bn3 = nn.BatchNorm2d(out_channels)\n        \n        self.drop2d = nn.Dropout2d(p=0.2)      # batchnorm alone leads to overfitting\n\n    def forward(self, input):\n        shortcut = self.shortcut(input)\n        input = nn.ReLU()(self.bn1(self.conv1(input)))\n        input = self.drop2d(input)\n        input = nn.ReLU()(self.bn2(self.conv2(input)))\n        input = self.drop2d(input)\n        input = nn.ReLU()(self.bn3(self.conv3(input)))\n        input = input + shortcut\n        return nn.ReLU()(input)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:02.264941Z","iopub.execute_input":"2022-05-15T22:03:02.26516Z","iopub.status.idle":"2022-05-15T22:03:02.276889Z","shell.execute_reply.started":"2022-05-15T22:03:02.265134Z","shell.execute_reply":"2022-05-15T22:03:02.276048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNet(nn.Module):\n    def __init__(self, in_channels, resblock, repeat, useBottleneck=False, outputs=397):\n        super().__init__()\n        self.layer0 = nn.Sequential(\n            nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU()\n        )\n\n        if useBottleneck:\n            filters = [64, 256, 512, 1024, 2048]\n            self.meta_rep = 128\n        else:\n            filters = [64, 64, 128, 256, 512]\n            self.meta_rep = 32\n\n        self.layer1 = nn.Sequential()\n        self.layer1.add_module('conv2_1', resblock(filters[0], filters[1], downsample=False))\n        for i in range(1, repeat[0]):\n                self.layer1.add_module('conv2_%d'%(i+1,), resblock(filters[1], filters[1], downsample=False))\n\n        self.layer2 = nn.Sequential()\n        self.layer2.add_module('conv3_1', resblock(filters[1], filters[2], downsample=True))\n        for i in range(1, repeat[1]):\n                self.layer2.add_module('conv3_%d' % (i+1,), resblock(filters[2], filters[2], downsample=False))\n\n        self.layer3 = nn.Sequential()\n        self.layer3.add_module('conv4_1', resblock(filters[2], filters[3], downsample=True))\n        for i in range(1, repeat[2]):\n            self.layer3.add_module('conv2_%d' % (i+1,), resblock(filters[3], filters[3], downsample=False))\n\n        self.layer4 = nn.Sequential()\n        self.layer4.add_module('conv5_1', resblock(filters[3], filters[4], downsample=True))\n        for i in range(1, repeat[3]):\n            self.layer4.add_module('conv3_%d'%(i+1,), resblock(filters[4], filters[4], downsample=False))\n\n        self.gap = torch.nn.AdaptiveAvgPool2d(1)\n        self.fc = torch.nn.Linear(filters[4] + self.meta_rep*3, outputs)\n        self.drop = nn.Dropout(p=0.4)\n\n    def forward(self, input):\n        \n        D = input[0]  # data\n        M = input[1]  # meta\n        Lat = M[:,0].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        Lon = M[:,1].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        Date = M[:,2].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        \n        D = self.layer0(D)\n        D = self.layer1(D)\n        D = self.layer2(D)\n        D = self.layer3(D)\n        D = self.layer4(D)\n        D = self.gap(D)                # [64, feature_maps, h, w] -> [64, feature_maps, 1]\n        \n        D = D.view(D.shape[0], -1)     # [64, feature_maps, 1, 1]    ->  [64, feature_maps]\n        D = self.drop(D)\n        \n        DM = torch.cat((D, Lat, Lon, Date),1)    # data & meta\n        \n        DM = self.fc(DM)\n\n        return DM","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:02.279062Z","iopub.execute_input":"2022-05-15T22:03:02.279288Z","iopub.status.idle":"2022-05-15T22:03:02.300711Z","shell.execute_reply.started":"2022-05-15T22:03:02.279262Z","shell.execute_reply":"2022-05-15T22:03:02.300116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model: torch.nn.Module) -> int:\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:02.301948Z","iopub.execute_input":"2022-05-15T22:03:02.302168Z","iopub.status.idle":"2022-05-15T22:03:02.314674Z","shell.execute_reply.started":"2022-05-15T22:03:02.30214Z","shell.execute_reply":"2022-05-15T22:03:02.314121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the device to use\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f'Using device: {device}') \n\n# resnet50\nresnet50 = ResNet(1, ResBottleneckBlock, [3, 4, 6, 3], useBottleneck=True, outputs=397)\nprint('Model initialization')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:02.31604Z","iopub.execute_input":"2022-05-15T22:03:02.31666Z","iopub.status.idle":"2022-05-15T22:03:02.525046Z","shell.execute_reply.started":"2022-05-15T22:03:02.316629Z","shell.execute_reply":"2022-05-15T22:03:02.524253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Soundscapes","metadata":{}},{"cell_type":"code","source":"# load model on cpu\n\nmodel = ResNet34(in_channels = 1, resblock = ResBlock1)\nmodel.to(device)\n\n# model = resnet50\n# model.to(device)\n\nprint(f'Number of parameters: {count_parameters(model)}')\nmodel.load_state_dict(torch.load('../input/models/ResNet34.pt', map_location=torch.device('cpu')))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:02.527774Z","iopub.execute_input":"2022-05-15T22:03:02.528003Z","iopub.status.idle":"2022-05-15T22:03:02.654035Z","shell.execute_reply.started":"2022-05-15T22:03:02.527974Z","shell.execute_reply":"2022-05-15T22:03:02.653134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_TEST_landscape_spectrograms(audio_path, output_dir):\n    \n    sig, rate = librosa.load(audio_path, sr=SAMPLING_RATE, offset=None)\n    \n    lunp_samples = int(INPUT_LENGTH*SAMPLING_RATE)   # number of time samples in a 5s piece of signal (5s*32000Hz)\n    \n    # split signal into five second lumps\n    sig_splits = []\n    for i in range(0, len(sig), lunp_samples):\n        split = sig[i:i + lunp_samples]\n\n        # End of signal\n        if len(split) < lunp_samples:\n            break\n        sig_splits.append(split)\n    \n    # extract mel spectrograms\n    split_count = 0\n    samples = []\n    for lump in sig_splits:\n        \n        HOP_LENGTH = int((INPUT_LENGTH*SAMPLING_RATE)/(SPEC_SHAPE[1]-1))\n        mel_spec = librosa.feature.melspectrogram(y=lump,\n                                                 sr=SAMPLING_RATE,\n                                                 n_fft=1024,\n                                                 hop_length=HOP_LENGTH,\n                                                 n_mels=SPEC_SHAPE[0],\n                                                 fmin=FMIN,\n                                                 fmax=FMAX)\n        \n        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n    \n        # Normalize\n        mel_spec -= mel_spec.min()\n        mel_spec /= mel_spec.max()\n        \n        # Save as image file\n        # THIS TIME IN A SINGLE FOLDER (NO LABELS):\n        spec_5s_name = audio_path.rsplit(os.sep, 1)[-1].rsplit('_',1)[0] + '_' + str((split_count+1)*5) + '.png'\n        specs_names.append(spec_5s_name)\n        save_path = os.path.join(output_dir, spec_5s_name)\n        \n        im = Image.fromarray(mel_spec * 255.0).convert(\"L\") # color -> greyscale (mode “L”): L = R * 299/1000 + G * 587/1000 + B * 114/1000\n        im.save(save_path)\n        \n        samples.append(save_path)\n        split_count += 1\n            \n    filename = audio_path.rsplit(os.sep, 1)[-1].rsplit('.', 1)[0]\n    location = filename.rsplit('_',2)[1]\n    meta_lat.append(geo_map[filename.rsplit('_',2)[1]][0])\n    meta_lon.append(geo_map[filename.rsplit('_',2)[1]][1])\n    date = filename.rsplit('_',1)[1][0:4] + '-' + filename.rsplit('_',1)[1][4:6] + '-' + filename.rsplit('_',1)[1][6:8]\n    meta_date.append(date_transform(date))\n    return samples","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:02.655367Z","iopub.execute_input":"2022-05-15T22:03:02.655582Z","iopub.status.idle":"2022-05-15T22:03:02.670924Z","shell.execute_reply.started":"2022-05-15T22:03:02.655556Z","shell.execute_reply":"2022-05-15T22:03:02.669756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ndef natural_sort(l): \n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n    return sorted(l, key=alphanum_key)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:02.67224Z","iopub.execute_input":"2022-05-15T22:03:02.672614Z","iopub.status.idle":"2022-05-15T22:03:02.686404Z","shell.execute_reply.started":"2022-05-15T22:03:02.672579Z","shell.execute_reply":"2022-05-15T22:03:02.685778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TEST SOUNDSCAPES\nimport librosa\n\ndef list_files(path):\n    return [f for f in os.listdir(path) if f.rsplit('.', 1)[-1] in ['ogg']]      # return name list audio.ogg\n\n# if commit: test folder not populated; if rerun by kaggle: test folder populated\ninput_dir = '../input/birdclef-2021/test_soundscapes'\naudio_list = list_files(input_dir)\nif len(audio_list) == 0:\n    input_dir = '../input/birdclef-2021/train_soundscapes'\n    audio_list = list_files(input_dir)\n\noutput_dir = './TEST_SOUNDSCAPES_MEL_DATASET'\nos.makedirs(output_dir)\nTEST_SPECS = []\ngeo_map = {'COL': [5.57,-75.85], 'COR':[10.12, -84.51], 'SNE':[38.49,-119.95], 'SSW':[42.47,-76.45]}\nmeta_lat = []\nmeta_lon = []\nmeta_date = []\n\nspecs_names = []\n\nfor filename in audio_list:\n    audio_file_path = os.path.join(input_dir, filename)\n    TEST_SPECS += get_TEST_landscape_spectrograms(audio_file_path, output_dir)\n\nprint('SUCCESSFULLY EXTRACTED {} SPECTROGRAMS'.format(len(TEST_SPECS)))  # 2400","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:02.687816Z","iopub.execute_input":"2022-05-15T22:03:02.688401Z","iopub.status.idle":"2022-05-15T22:03:37.400851Z","shell.execute_reply.started":"2022-05-15T22:03:02.688357Z","shell.execute_reply":"2022-05-15T22:03:37.399947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree('./TEST_SOUNDSCAPES_MEL_DATASET')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:37.403018Z","iopub.execute_input":"2022-05-15T22:03:37.403868Z","iopub.status.idle":"2022-05-15T22:03:37.408576Z","shell.execute_reply.started":"2022-05-15T22:03:37.403813Z","shell.execute_reply":"2022-05-15T22:03:37.407696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# META\nmeta_sound_df = pd.DataFrame(list(zip(meta_lat, meta_lon, meta_date)), columns =['latitude', 'longitude', 'date'])\nprint(meta_sound_df)\n\n# NORMALIZE \nfor idx, col in enumerate(['latitude', 'longitude', 'date']):\n    meta_sound_df[col] = ( meta_sound_df[col] - META_MEAN[idx] ) / META_STD[idx]\n\na = meta_sound_df.columns    \n# REPEAT: repeat each row in meta_sound_df 600s/5s times:\nmeta_sound_df = pd.DataFrame(np.repeat(meta_sound_df.values, 120, axis=0))\nmeta_sound_df.columns = a\nmeta_sound_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:37.411254Z","iopub.execute_input":"2022-05-15T22:03:37.413135Z","iopub.status.idle":"2022-05-15T22:03:37.462989Z","shell.execute_reply.started":"2022-05-15T22:03:37.413075Z","shell.execute_reply":"2022-05-15T22:03:37.462051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_sound_tensor = torch.tensor([meta_sound_df['latitude'].values, meta_sound_df['longitude'].values, meta_sound_df['date'].values]).float()\nmeta_sound_tensor = torch.transpose(meta_sound_tensor, 0, 1)\nmeta_sound_tensor, meta_sound_tensor.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:37.465847Z","iopub.execute_input":"2022-05-15T22:03:37.46781Z","iopub.status.idle":"2022-05-15T22:03:37.494181Z","shell.execute_reply.started":"2022-05-15T22:03:37.46775Z","shell.execute_reply":"2022-05-15T22:03:37.493234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_inference =  transforms.Compose([transforms.Grayscale(), \n                                           transforms.ToTensor(), \n                                           transforms.Normalize(mean=DATA_MEAN, std=DATA_STD)])\ndef image_loader(image_path):\n    \"\"\"load image, returns cuda tensor\"\"\"\n    image = Image.open(image_path)\n    image = transform_inference(image)\n    image = image.unsqueeze(0)  # adds dimension 0 of size 1 (batch dim) to obtain 1x1x48x128\n    if device.type == 'cuda':\n        return image.cuda()\n    else:\n        return image","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:37.497038Z","iopub.execute_input":"2022-05-15T22:03:37.499018Z","iopub.status.idle":"2022-05-15T22:03:37.5161Z","shell.execute_reply.started":"2022-05-15T22:03:37.498953Z","shell.execute_reply":"2022-05-15T22:03:37.514981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row_list = natural_sort(specs_names)\nCOL_list = []\nCOR_list = []\nSNE_list = []\nSSW_list = []\nfor row in row_list:\n    if 'COL' in row:\n        COL_list.append(row)\n    if 'COR' in row:\n        COR_list.append(row)\n    if 'SNE' in row:\n        SNE_list.append(row)\n    if 'SSW' in row:\n        SSW_list.append(row)\n        \nordered_list = COL_list + COR_list + SNE_list + SSW_list      # sort submission.csv according to this list","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:37.517421Z","iopub.execute_input":"2022-05-15T22:03:37.517661Z","iopub.status.idle":"2022-05-15T22:03:37.548725Z","shell.execute_reply.started":"2022-05-15T22:03:37.517631Z","shell.execute_reply":"2022-05-15T22:03:37.548017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# birds_as_nocalls10 = list(['balori', 'bkcchi', 'bobfly1', 'chswar', 'comyel', 'eastow', 'gockin', 'reevir1', 'rewbla', 'rucwar', 'sonspa'])\n# birds_as_nocalls15 = list(['bkcchi', 'bobfly1', 'comyel', 'reevir1', 'rewbla', 'rucwar', 'sonspa'])","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:37.549647Z","iopub.execute_input":"2022-05-15T22:03:37.550279Z","iopub.status.idle":"2022-05-15T22:03:37.553733Z","shell.execute_reply.started":"2022-05-15T22:03:37.550242Z","shell.execute_reply":"2022-05-15T22:03:37.552725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list in a dataframe pair of birds frequently heard together\nfrom itertools import combinations\ntruth = pd.read_csv('../input/birdclef-2021/train_soundscape_labels.csv')\n\ngroups = truth[truth['birds'].str.split().str.len() > 1]\ngroups['birds'] = groups['birds'].apply(lambda x: list(combinations(x.split(' '), 2)))\npairs = groups.explode('birds', ignore_index=True)\npairs_count = pd.DataFrame(np.stack(np.unique(pairs['birds'], return_counts = True), axis = 1),\n                                   columns = ['birds', 'occurrences'])\ncommon_pairs = pairs_count[pairs_count['occurrences']>10]    # maybe there are few pairs in hidden test set\ncommon_pairs['birds'] = [' '.join(map(str, l)) for l in common_pairs['birds']]\ncommon_pairs = common_pairs.sort_values(by=['occurrences'], ascending=False)\ncommon_pairs","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:37.555667Z","iopub.execute_input":"2022-05-15T22:03:37.556432Z","iopub.status.idle":"2022-05-15T22:03:37.59016Z","shell.execute_reply.started":"2022-05-15T22:03:37.556386Z","shell.execute_reply":"2022-05-15T22:03:37.589298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict MULTILABEL\ntest_soundscapes_dir =  './TEST_SOUNDSCAPES_MEL_DATASET'\nfrom torch.nn import AvgPool2d\nfrom collections import deque\n\nCol_averager = AvgPool2d(kernel_size =(6,128*4))                     # 20 seconds\nPatch_averager = AvgPool2d(kernel_size =(6,4))\nlast_saved = 0          # saved last_birds number (between these, accept lower probabilities for species1)\nX = 10                  # number of highest score guesses to check for birds related to species1 (multilabel)\nmultilabel = False      # multi-birds label is inaccurate\n\n# Store the results\ndata = {'row_id': [], 'birds': [], 'score': []}\nwith torch.no_grad():\n    cnt = 0\n    last_birds = deque(maxlen=last_saved)\n    for idx, spec_name in enumerate(ordered_list):\n        if idx % 120 == 0:                               # new 10 minutes audio (120*5s)\n            last_birds = deque(maxlen=last_saved)\n            # print('audio n. ', int(idx/120))\n        path = os.path.join(test_soundscapes_dir, spec_name)\n        \n        spec = image_loader(path)\n        meta = meta_sound_tensor[idx].unsqueeze(0)\n        spec, meta = spec.to(device), meta.to(device)\n        model.eval()\n        \n        # repeat 2/4/6 times to reach 10/20/30 seconds\n        spec = torch.cat((spec, spec, spec, spec),-1)               # 20 seconds\n        prediction = nn.functional.softmax(model([spec, meta]))[0]\n        prediction = torch.Tensor.cpu(prediction)\n        \n        # store 1st, 2nd and first X guesses (the latter to be used in case of birds frequently heard together)\n        idx2,idx1 = np.argpartition(prediction, -2)[-2:]            # indices of the 2 highest scores (max on the right)\n        bestX_idx = np.argpartition(prediction, -X)[-X:]            # indices of the X highest scores\n        species1, species2 = all_species[idx1], all_species[idx2]\n        score1, score2 = prediction[idx1], prediction[idx2]         # 2 highest scores\n        bestX = list(all_species[bestX_idx])                        # X highest scores\n        bestX.remove(species1)                                      # (species1 removed)\n        \n        data['row_id'].append(spec_name.rsplit('.', 1)[0])\n        \n        # filter2: separate birdcalls | nocalls\n        AvgCol = Col_averager(spec)            # 1x1x8x1\n        AvgPatches = Patch_averager(spec)      # 1x1x8x128\n        diff = AvgPatches - AvgCol             # 1x1x8x128\n        diff = diff.view(diff.shape[0], -1)    # 1x(8*128)\n        birdcall = np.any(np.absolute(np.array(torch.Tensor.cpu(diff)))>0.63, axis=1)\n        \n        bird2_flag = 0\n        if birdcall and (species1 != 'grhowl') and (score1>0.33 or (last_birds.count(species1)>=3 and score1>0.15)):# or (species1 in birds_as_nocalls10 and score1>0.3):\n            last_birds.append(species1)\n            if len(common_pairs):\n                has_rel_birds = common_pairs['birds'].str.contains(species1)                   # if 'common_pairs' rows contain species1\n                if any(has_rel_birds):\n                    rel_pairs = pd.DataFrame(common_pairs.loc[has_rel_birds])                  # rows containing species1\n                    bestX_pattern = '|'.join(bestX)\n                    rel_pairs['in_bestX'] = rel_pairs['birds'].str.contains(bestX_pattern)     # rows True if bird2 in row is in bestX\n                    rel_pairs_inbestX = rel_pairs.loc[rel_pairs['in_bestX']]['birds'].to_list()   # list of pairs with bird2 in bestX\n                    if rel_pairs_inbestX:\n                        rel_bird = rel_pairs_inbestX[0].rsplit(' ')            # keep first pair, split it\n                        rel_bird.remove(species1)                           # bird related to species1\n                        rel_bird = str(rel_bird)\n                        bird2_flag = 1\n                        species2 = rel_bird\n\n            if score1 < 0.40:     # add 'nocall' label anyway\n                if multilabel and bird2_flag:\n                    data['birds'].append({species1, species2, 'nocall'})\n                    cnt +=2\n                else:\n                    data['birds'].append({species1, 'nocall'})\n                    cnt += 1\n            else:\n                if multilabel and bird2_flag:\n                    data['birds'].append({species1, species2})\n                    cnt +=2\n                else:\n                    data['birds'].append({species1})\n                    cnt += 1\n        else:\n            data['birds'].append({'nocall'})\n        # Add the confidence score\n        data['score'].append( str(score1.item()) + ' ' + str(score2.item()) )\n\nprint('SOUNDSCAPE ANALYSIS DONE. FOUND {} BIRDS.'.format(cnt))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:03:37.591631Z","iopub.execute_input":"2022-05-15T22:03:37.592118Z","iopub.status.idle":"2022-05-15T22:06:15.770782Z","shell.execute_reply.started":"2022-05-15T22:03:37.592085Z","shell.execute_reply":"2022-05-15T22:06:15.76935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.rmtree('./TEST_SOUNDSCAPES_MEL_DATASET')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:06:15.772344Z","iopub.execute_input":"2022-05-15T22:06:15.773236Z","iopub.status.idle":"2022-05-15T22:06:15.869411Z","shell.execute_reply.started":"2022-05-15T22:06:15.773192Z","shell.execute_reply":"2022-05-15T22:06:15.86815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sets to strings\nprediction_dict = {'row_id' : [], 'birds' : []}\nfor row in data['row_id']:\n    prediction_dict['row_id'].append(row)\n\nfor row in data['birds']:\n    prediction_dict['birds'].append(' '.join(row))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:06:15.871035Z","iopub.execute_input":"2022-05-15T22:06:15.871362Z","iopub.status.idle":"2022-05-15T22:06:15.879409Z","shell.execute_reply.started":"2022-05-15T22:06:15.871316Z","shell.execute_reply":"2022-05-15T22:06:15.878396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create submission file\nsubmission = pd.DataFrame(prediction_dict, columns = ['row_id', 'birds'])\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:06:15.880978Z","iopub.execute_input":"2022-05-15T22:06:15.881838Z","iopub.status.idle":"2022-05-15T22:06:15.903816Z","shell.execute_reply.started":"2022-05-15T22:06:15.881791Z","shell.execute_reply":"2022-05-15T22:06:15.902528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:06:15.907362Z","iopub.execute_input":"2022-05-15T22:06:15.90761Z","iopub.status.idle":"2022-05-15T22:06:15.924732Z","shell.execute_reply.started":"2022-05-15T22:06:15.907582Z","shell.execute_reply":"2022-05-15T22:06:15.923941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame(data, columns = ['row_id', 'birds', 'score'])       # new dataframe\nresults.rename(columns = {'birds':'prediction'}, inplace = True)\nresults = pd.merge(truth, results, on='row_id')                            # merge with true labels\n\n# Let's look at some entries\nresults[1076:1086]","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:06:15.926238Z","iopub.execute_input":"2022-05-15T22:06:15.926817Z","iopub.status.idle":"2022-05-15T22:06:15.96204Z","shell.execute_reply.started":"2022-05-15T22:06:15.926768Z","shell.execute_reply":"2022-05-15T22:06:15.9609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_species_nocall = np.append('nocall', all_species)\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer(classes = all_species_nocall)\n\ny_prediction = list(results['prediction'])\ny_pred_matrix = mlb.fit_transform(y_prediction)\n\n# true birds list to list of sets\ny_truth = []\nfor element in list(results['birds']):\n    y_truth.append(set(element.split()))\ny_true_matrix = mlb.fit_transform(y_truth)\n\nf1 = f1_score(y_true_matrix, y_pred_matrix, average='micro')\nprint('F1 = %.3f' %(f1))\n\n# f1_398 = f1_score(y_true_matrix, y_pred_matrix, average=None)            # f1 for each class\n# print('\\n', 'F1_classes:\\n', f1_398)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T22:06:15.96397Z","iopub.execute_input":"2022-05-15T22:06:15.964281Z","iopub.status.idle":"2022-05-15T22:06:16.090594Z","shell.execute_reply.started":"2022-05-15T22:06:15.964249Z","shell.execute_reply":"2022-05-15T22:06:16.088979Z"},"trusted":true},"execution_count":null,"outputs":[]}]}