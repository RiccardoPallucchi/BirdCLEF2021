{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm.notebook import tqdm, trange\nimport os\nfrom typing import Mapping, Union, Optional, Callable, Dict\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import Dataset, Subset, DataLoader, SubsetRandomSampler, TensorDataset, ConcatDataset\nimport warnings\nwarnings.filterwarnings(action='ignore')","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:12:15.657756Z","iopub.execute_input":"2022-05-12T13:12:15.658674Z","iopub.status.idle":"2022-05-12T13:12:17.565233Z","shell.execute_reply.started":"2022-05-12T13:12:15.658534Z","shell.execute_reply":"2022-05-12T13:12:17.564122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset and data distribution","metadata":{}},{"cell_type":"code","source":"SAMPLING_RATE = 32000 # Hertz\nINPUT_LENGTH = 5      # seconds\nSPEC_SHAPE = (48,128) # spectrogram shape\nFMIN=500              # Hz (~min frequency for birds)\nFMAX=12500            # Hz (~max frequency for birds)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:12:17.567258Z","iopub.execute_input":"2022-05-12T13:12:17.567545Z","iopub.status.idle":"2022-05-12T13:12:17.572662Z","shell.execute_reply.started":"2022-05-12T13:12:17.567511Z","shell.execute_reply":"2022-05-12T13:12:17.571846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_MEAN = 0.3674\nDATA_STD = 0.1928\n\nMETA_MEAN = [24.472804615395624, -79.96082831218337, 162.2867799090244, 619.9162929032668]\nMETA_STD = [22.10848093451316, 38.37072607349947, 88.93816236402917, 266.60113126777134]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-12T13:12:17.57438Z","iopub.execute_input":"2022-05-12T13:12:17.575073Z","iopub.status.idle":"2022-05-12T13:12:17.583985Z","shell.execute_reply.started":"2022-05-12T13:12:17.57504Z","shell.execute_reply":"2022-05-12T13:12:17.583298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metadata","metadata":{}},{"cell_type":"code","source":"# Load metadata file\nmetadata_df = pd.read_csv('../input/birdclef-2021/train_metadata.csv')\nall_species = metadata_df['primary_label'].unique()\nmeta_df = metadata_df[[\"filename\",\"primary_label\",\"latitude\",\"longitude\",\"date\",\"time\",\"rating\"]]  # retain\n# TIME OF DAY NOT PRESENT ON TEST DATA: USELESS\nmeta_df","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:12:17.586208Z","iopub.execute_input":"2022-05-12T13:12:17.586887Z","iopub.status.idle":"2022-05-12T13:12:18.150474Z","shell.execute_reply.started":"2022-05-12T13:12:17.586842Z","shell.execute_reply":"2022-05-12T13:12:18.149697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.mode.chained_assignment = None  # default='warn'\n\n# express DATE in days (remove year)\ndef date_transform(date):\n    return int(date.rsplit('-')[2]) + max(0, int(date.rsplit('-')[1])-1)*30\nmeta_df['date'] = meta_df['date'].apply(date_transform)\n\n# express TIME in minutes\ndef time_transform(time):\n   # exclude '?', 'xx', 'xx:xx', 'night', 'am'\n    if not(any(map(str.isdigit, time))):     # if no numbers inside\n        return np.random.randint(0,1440)     # method1: in this way we will not increase a specific time slot\n    else:\n        Q = 0\n        time = time.lower()                  # AM,PM->am,pm\n        if 'pm' in time:\n            Q = 1\n        time = time.replace('pm','')\n        time = time.replace('am','')\n        time = time.rsplit(':')\n        minutes = 0\n        if len(time)>1:\n            minutes = int(time[1])\n        result = (int(time[0]) + Q*12)*60 + minutes\n        return( result%1440 )                # there are also '12:30pm', '12:15pm', '24:15', etc\nmeta_df['time'] = meta_df['time'].apply(time_transform)\nmeta_df","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:12:18.151727Z","iopub.execute_input":"2022-05-12T13:12:18.152121Z","iopub.status.idle":"2022-05-12T13:12:18.492865Z","shell.execute_reply.started":"2022-05-12T13:12:18.152089Z","shell.execute_reply":"2022-05-12T13:12:18.491946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The model","metadata":{}},{"cell_type":"code","source":"class ResBottleneckBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, downsample):\n        super().__init__()\n        self.downsample = downsample\n        self.conv1 = nn.Conv2d(in_channels, out_channels//4, kernel_size=1, stride=1)\n        self.conv2 = nn.Conv2d(out_channels//4, out_channels//4, kernel_size=3, stride=2 if downsample else 1, padding=1)\n        self.conv3 = nn.Conv2d(out_channels//4, out_channels, kernel_size=1, stride=1)\n        self.shortcut = nn.Sequential()\n        \n        if self.downsample or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2 if self.downsample else 1),\n                nn.BatchNorm2d(out_channels)\n            )\n\n        self.bn1 = nn.BatchNorm2d(out_channels//4)\n        self.bn2 = nn.BatchNorm2d(out_channels//4)\n        self.bn3 = nn.BatchNorm2d(out_channels)\n        \n        self.drop2d = nn.Dropout2d(p=0.2)      # batchnorm alone leads to overfitting\n\n    def forward(self, input):\n        shortcut = self.shortcut(input)\n        input = nn.ReLU()(self.bn1(self.conv1(input)))\n        input = self.drop2d(input)\n        input = nn.ReLU()(self.bn2(self.conv2(input)))\n        input = self.drop2d(input)\n        input = nn.ReLU()(self.bn3(self.conv3(input)))\n        input = input + shortcut\n        return nn.ReLU()(input)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:12:18.494313Z","iopub.execute_input":"2022-05-12T13:12:18.494558Z","iopub.status.idle":"2022-05-12T13:12:18.507713Z","shell.execute_reply.started":"2022-05-12T13:12:18.494528Z","shell.execute_reply":"2022-05-12T13:12:18.506588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNet(nn.Module):\n    def __init__(self, in_channels, resblock, repeat, useBottleneck=False, outputs=397):\n        super().__init__()\n        self.layer0 = nn.Sequential(\n            nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU()\n        )\n\n        if useBottleneck:\n            filters = [64, 256, 512, 1024, 2048]\n            self.meta_rep = 128\n        else:\n            filters = [64, 64, 128, 256, 512]\n            self.meta_rep = 32\n\n        self.layer1 = nn.Sequential()\n        self.layer1.add_module('conv2_1', resblock(filters[0], filters[1], downsample=False))\n        for i in range(1, repeat[0]):\n                self.layer1.add_module('conv2_%d'%(i+1,), resblock(filters[1], filters[1], downsample=False))\n\n        self.layer2 = nn.Sequential()\n        self.layer2.add_module('conv3_1', resblock(filters[1], filters[2], downsample=True))\n        for i in range(1, repeat[1]):\n                self.layer2.add_module('conv3_%d' % (i+1,), resblock(filters[2], filters[2], downsample=False))\n\n        self.layer3 = nn.Sequential()\n        self.layer3.add_module('conv4_1', resblock(filters[2], filters[3], downsample=True))\n        for i in range(1, repeat[2]):\n            self.layer3.add_module('conv2_%d' % (i+1,), resblock(filters[3], filters[3], downsample=False))\n\n        self.layer4 = nn.Sequential()\n        self.layer4.add_module('conv5_1', resblock(filters[3], filters[4], downsample=True))\n        for i in range(1, repeat[3]):\n            self.layer4.add_module('conv3_%d'%(i+1,), resblock(filters[4], filters[4], downsample=False))\n\n        self.gap = torch.nn.AdaptiveAvgPool2d(1)\n        self.fc = torch.nn.Linear(filters[4] + self.meta_rep*3, outputs)\n        self.drop = nn.Dropout(p=0.4)\n\n    def forward(self, input):\n        \n        D = input[0]  # data\n        M = input[1]  # meta\n        Lat = M[:,0].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        Lon = M[:,1].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        Date = M[:,2].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        \n        D = self.layer0(D)\n        D = self.layer1(D)\n        D = self.layer2(D)\n        D = self.layer3(D)\n        D = self.layer4(D)\n        D = self.gap(D)                # [64, feature_maps, h, w] -> [64, feature_maps, 1]\n        \n        D = D.view(D.shape[0], -1)     # [64, feature_maps, 1, 1]    ->  [64, feature_maps]\n        D = self.drop(D)\n        \n        DM = torch.cat((D, Lat, Lon, Date),1)    # data & meta\n        \n        DM = self.fc(DM)\n\n        return DM","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:12:18.509461Z","iopub.execute_input":"2022-05-12T13:12:18.509706Z","iopub.status.idle":"2022-05-12T13:12:18.535954Z","shell.execute_reply.started":"2022-05-12T13:12:18.509679Z","shell.execute_reply":"2022-05-12T13:12:18.534895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the device to use\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f'Using device: {device}') \n\n# resnet50\nresnet50 = ResNet(1, ResBottleneckBlock, [3, 4, 6, 3], useBottleneck=True, outputs=397)\nresnet50.to(device)\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:12:18.537249Z","iopub.execute_input":"2022-05-12T13:12:18.537713Z","iopub.status.idle":"2022-05-12T13:12:18.841089Z","shell.execute_reply.started":"2022-05-12T13:12:18.537675Z","shell.execute_reply":"2022-05-12T13:12:18.840228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model: torch.nn.Module) -> int:\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:12:18.842467Z","iopub.execute_input":"2022-05-12T13:12:18.842707Z","iopub.status.idle":"2022-05-12T13:12:18.847688Z","shell.execute_reply.started":"2022-05-12T13:12:18.842676Z","shell.execute_reply":"2022-05-12T13:12:18.84673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Soundscapes","metadata":{}},{"cell_type":"code","source":"# on cpu\nmodel = resnet50\nmodel.load_state_dict(torch.load('../input/net50-meta128-masks-timerec-09051425/Net50_meta128_masks_timerec_09-05--14-25.pt', \n                                 map_location=torch.device('cpu')))","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:12:18.850948Z","iopub.execute_input":"2022-05-12T13:12:18.851181Z","iopub.status.idle":"2022-05-12T13:12:20.658966Z","shell.execute_reply.started":"2022-05-12T13:12:18.851154Z","shell.execute_reply":"2022-05-12T13:12:20.657986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_TEST_landscape_spectrograms(audio_path, output_dir):\n    \n    sig, rate = librosa.load(audio_path, sr=SAMPLING_RATE, offset=None)\n    \n    lunp_samples = int(INPUT_LENGTH*SAMPLING_RATE)   # number of time samples in a 5s piece of signal (5s*32000Hz)\n    \n    # split signal into five second lumps\n    sig_splits = []\n    for i in range(0, len(sig), lunp_samples):\n        split = sig[i:i + lunp_samples]\n\n        # End of signal\n        if len(split) < lunp_samples:\n            break\n        sig_splits.append(split)\n    \n    # extract mel spectrograms\n    split_count = 0\n    samples = []\n    for lump in sig_splits:\n        \n        HOP_LENGTH = int((INPUT_LENGTH*SAMPLING_RATE)/(SPEC_SHAPE[1]-1))\n        mel_spec = librosa.feature.melspectrogram(y=lump,\n                                                 sr=SAMPLING_RATE,\n                                                 n_fft=1024,\n                                                 hop_length=HOP_LENGTH,\n                                                 n_mels=SPEC_SHAPE[0],\n                                                 fmin=FMIN,\n                                                 fmax=FMAX)\n        \n        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n    \n        # Normalize\n        mel_spec -= mel_spec.min()\n        mel_spec /= mel_spec.max()\n        \n        # Save as image file\n        # THIS TIME IN A SINGLE FOLDER (NO LABELS):\n        spec_5s_name = audio_path.rsplit(os.sep, 1)[-1].rsplit('_',1)[0] + '_' + str((split_count+1)*5) + '.png'\n        specs_names.append(spec_5s_name)\n        save_path = os.path.join(output_dir, audio_path.rsplit(os.sep, 1)[-1].rsplit('.', 1)[0].rsplit('_',1)[0] + \n                                 '_' + str((split_count+1)*5) + '.png')\n        \n        im = Image.fromarray(mel_spec * 255.0).convert(\"L\") # color -> greyscale (mode “L”): L = R * 299/1000 + G * 587/1000 + B * 114/1000\n        im.save(save_path)\n        \n        samples.append(save_path)\n        split_count += 1\n            \n    filename = audio_path.rsplit(os.sep, 1)[-1].rsplit('.', 1)[0]\n    location = filename.rsplit('_',2)[1]\n    meta_lat.append(geo_map[filename.rsplit('_',2)[1]][0])\n    meta_lon.append(geo_map[filename.rsplit('_',2)[1]][1])\n    date = filename.rsplit('_',1)[1][0:4] + '-' + filename.rsplit('_',1)[1][4:6] + '-' + filename.rsplit('_',1)[1][6:8]\n    meta_date.append(date_transform(date))\n    return samples","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:52:16.664112Z","iopub.execute_input":"2022-05-12T13:52:16.664448Z","iopub.status.idle":"2022-05-12T13:52:16.684086Z","shell.execute_reply.started":"2022-05-12T13:52:16.664418Z","shell.execute_reply":"2022-05-12T13:52:16.683341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ndef natural_sort(l): \n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n    return sorted(l, key=alphanum_key)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:52:29.400825Z","iopub.execute_input":"2022-05-12T13:52:29.401242Z","iopub.status.idle":"2022-05-12T13:52:29.406586Z","shell.execute_reply.started":"2022-05-12T13:52:29.401211Z","shell.execute_reply":"2022-05-12T13:52:29.405884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TEST SOUNDSCAPES\nimport librosa\n\ndef list_files(path):\n    return [f for f in os.listdir(path) if f.rsplit('.', 1)[-1] in ['ogg']]      # return name list audio.ogg\n\n# if commit: test folder not populated; if rerun by kaggle: test folder populated\ninput_dir = '../input/birdclef-2021/test_soundscapes'\naudio_list = list_files(input_dir)\nif len(audio_list) == 0:\n    input_dir = '../input/birdclef-2021/train_soundscapes'\n    audio_list = list_files(input_dir)\n\noutput_dir = './TEST_SOUNDSCAPES_MEL_DATASET'\nos.makedirs(output_dir)\nTEST_SPECS = []\ngeo_map = {'COL': [5.57,-75.85], 'COR':[10.12, -84.51], 'SNE':[38.49,-119.95], 'SSW':[42.47,-76.45]}\nmeta_lat = []\nmeta_lon = []\nmeta_date = []\n\nspecs_names = []\n\nfor filename in audio_list:\n    audio_file_path = os.path.join(input_dir, filename)\n    TEST_SPECS += get_TEST_landscape_spectrograms(audio_file_path, output_dir)\n\nprint('SUCCESSFULLY EXTRACTED {} SPECTROGRAMS'.format(len(TEST_SPECS)))  # 2400","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:52:30.457964Z","iopub.execute_input":"2022-05-12T13:52:30.458407Z","iopub.status.idle":"2022-05-12T13:53:08.531963Z","shell.execute_reply.started":"2022-05-12T13:52:30.458375Z","shell.execute_reply":"2022-05-12T13:53:08.528255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree('./TEST_SOUNDSCAPES_MEL_DATASET')","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:13:03.156011Z","iopub.execute_input":"2022-05-12T13:13:03.157039Z","iopub.status.idle":"2022-05-12T13:13:03.161923Z","shell.execute_reply.started":"2022-05-12T13:13:03.156979Z","shell.execute_reply":"2022-05-12T13:13:03.161059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# META\nmeta_sound_df = pd.DataFrame(list(zip(meta_lat, meta_lon, meta_date)), columns =['latitude', 'longitude', 'date'])\nprint(meta_sound_df)\n\n# NORMALIZE \nfor idx, col in enumerate(['latitude', 'longitude', 'date']):\n    meta_sound_df[col] = ( meta_sound_df[col] - META_MEAN[idx] ) / META_STD[idx]\n\na = meta_sound_df.columns    \n# REPEAT: repeat each row in meta_sound_df 600s/5s times:\nmeta_sound_df = pd.DataFrame(np.repeat(meta_sound_df.values, 120, axis=0))\nmeta_sound_df.columns = a\nmeta_sound_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:53:23.779402Z","iopub.execute_input":"2022-05-12T13:53:23.779853Z","iopub.status.idle":"2022-05-12T13:53:23.801149Z","shell.execute_reply.started":"2022-05-12T13:53:23.779814Z","shell.execute_reply":"2022-05-12T13:53:23.799809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_sound_tensor = torch.tensor([meta_sound_df['latitude'].values, meta_sound_df['longitude'].values, meta_sound_df['date'].values]).float()\nmeta_sound_tensor = torch.transpose(meta_sound_tensor, 0, 1)\nmeta_sound_tensor, meta_sound_tensor.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:53:24.527611Z","iopub.execute_input":"2022-05-12T13:53:24.52792Z","iopub.status.idle":"2022-05-12T13:53:24.539338Z","shell.execute_reply.started":"2022-05-12T13:53:24.527891Z","shell.execute_reply":"2022-05-12T13:53:24.53842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_inference =  transforms.Compose([transforms.Grayscale(), \n                                           transforms.ToTensor(), \n                                           transforms.Normalize(mean=DATA_MEAN, std=DATA_STD)])\ndef image_loader(image_path):\n    \"\"\"load image, returns cuda tensor\"\"\"\n    image = Image.open(image_path)\n    image = transform_inference(image)\n    image = image.unsqueeze(0)  # adds dimension 0 of size 1 (batch dim) to obtain 1x1x48x128\n    if device.type == 'cuda':\n        return image.cuda()\n    else:\n        return image","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:53:25.74812Z","iopub.execute_input":"2022-05-12T13:53:25.748749Z","iopub.status.idle":"2022-05-12T13:53:25.756464Z","shell.execute_reply.started":"2022-05-12T13:53:25.7487Z","shell.execute_reply":"2022-05-12T13:53:25.755362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row_list = natural_sort(specs_names)\nCOL_list = []\nCOR_list = []\nSNE_list = []\nSSW_list = []\nfor row in row_list:\n    if 'COL' in row:\n        COL_list.append(row)\n    if 'COR' in row:\n        COR_list.append(row)\n    if 'SNE' in row:\n        SNE_list.append(row)\n    if 'SSW' in row:\n        SSW_list.append(row)\n        \nordered_list = COL_list + COR_list + SNE_list + SSW_list      # sort submission.csv according to this list","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:53:26.838186Z","iopub.execute_input":"2022-05-12T13:53:26.838521Z","iopub.status.idle":"2022-05-12T13:53:26.861667Z","shell.execute_reply.started":"2022-05-12T13:53:26.838489Z","shell.execute_reply":"2022-05-12T13:53:26.860984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# birds_as_nocalls10 = list(['balori', 'bkcchi', 'bobfly1', 'chswar', 'comyel', 'eastow', 'gockin', 'reevir1', 'rewbla', 'rucwar', 'sonspa'])\n# birds_as_nocalls15 = list(['bkcchi', 'bobfly1', 'comyel', 'reevir1', 'rewbla', 'rucwar', 'sonspa'])","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:13:03.33696Z","iopub.execute_input":"2022-05-12T13:13:03.337318Z","iopub.status.idle":"2022-05-12T13:13:03.347956Z","shell.execute_reply.started":"2022-05-12T13:13:03.337283Z","shell.execute_reply":"2022-05-12T13:13:03.346954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list in a dataframe pair of birds frequently heard together\nfrom itertools import combinations\ntruth = pd.read_csv('../input/birdclef-2021/train_soundscape_labels.csv')\n\ngroups = truth[truth['birds'].str.split().str.len() > 1]\ngroups['birds'] = groups['birds'].apply(lambda x: list(combinations(x.split(' '), 2)))\npairs = groups.explode('birds', ignore_index=True)\npairs_count = pd.DataFrame(np.stack(np.unique(pairs['birds'], return_counts = True), axis = 1),\n                                   columns = ['birds', 'occurrences'])\ncommon_pairs = pairs_count[pairs_count['occurrences']>10]\ncommon_pairs['birds'] = [' '.join(map(str, l)) for l in common_pairs['birds']]\ncommon_pairs = common_pairs.sort_values(by=['occurrences'], ascending=False)\ncommon_pairs","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:53:37.014122Z","iopub.execute_input":"2022-05-12T13:53:37.014446Z","iopub.status.idle":"2022-05-12T13:53:37.048903Z","shell.execute_reply.started":"2022-05-12T13:53:37.014414Z","shell.execute_reply":"2022-05-12T13:53:37.048285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict MULTILABEL\ntest_soundscapes_dir =  './TEST_SOUNDSCAPES_MEL_DATASET'\nfrom torch.nn import AvgPool2d\nfrom collections import deque\n\nCol_averager = AvgPool2d(kernel_size =(6,128*4))                     # 20 seconds\nPatch_averager = AvgPool2d(kernel_size =(6,4))\nlast_saved = 0         # saved last_birds number (between these, accept lower probabilities for species1)\nX = 10                  # number of highest score guesses to check for birds related to species1 (multilabel)\nmultilabel = False\n\n# Store the results\ndata = {'row_id': [], 'birds': [], 'score': []}\nwith torch.no_grad():\n    cnt = 0\n    last_birds = deque(maxlen=last_saved)\n    for idx, spec_name in enumerate(ordered_list):\n        if idx % 120 == 0:                               # new 10 minutes audio (120*5s)\n            last_birds = deque(maxlen=last_saved)\n            print('audio n. ', int(idx/120))\n        path = os.path.join(test_soundscapes_dir, spec_name)\n        \n        spec = image_loader(path)\n        meta = meta_sound_tensor[idx].unsqueeze(0)\n        spec, meta = spec.to(device), meta.to(device)\n        model.eval()\n        \n        # repeat 2/4/6 times to reach 10/20/30 seconds\n        spec = torch.cat((spec, spec, spec, spec),-1)               # 20 seconds\n        prediction = nn.functional.softmax(model([spec, meta]))[0]\n        prediction = torch.Tensor.cpu(prediction)\n        \n        # store 1st, 2nd and first X guesses (the latter to be used in case of birds frequently heard together)\n        idx2,idx1 = np.argpartition(prediction, -2)[-2:]            # indices of the 2 highest scores (max on the right)\n        bestX_idx = np.argpartition(prediction, -X)[-X:]            # indices of the X highest scores\n        species1, species2 = all_species[idx1], all_species[idx2]\n        score1, score2 = prediction[idx1], prediction[idx2]         # 2 highest scores\n        bestX = list(all_species[bestX_idx])                        # X highest scores\n        bestX.remove(species1)                                      # (species1 removed)\n        \n        data['row_id'].append(spec_name.rsplit('.', 1)[0])\n        \n        # filter2: separate birdcalls | nocalls\n        AvgCol = Col_averager(spec)            # 1x1x8x1\n        AvgPatches = Patch_averager(spec)      # 1x1x8x128\n        diff = AvgPatches - AvgCol             # 1x1x8x128\n        diff = diff.view(diff.shape[0], -1)    # 1x(8*128)\n        birdcall = np.any(np.absolute(np.array(torch.Tensor.cpu(diff)))>0.63, axis=1)\n        \n        bird2_flag = 0\n        if birdcall and (species1 != 'grhowl') and (score1>0.28 or (last_birds.count(species1)>=3 and score1>0.15)):# or (species1 in birds_as_nocalls10 and score1>0.3):\n            last_birds.append(species1)\n            has_rel_birds = common_pairs['birds'].str.contains(species1)                   # if 'common_pairs' rows contain species1\n            if any(has_rel_birds):\n                rel_pairs = pd.DataFrame(common_pairs.loc[has_rel_birds])                  # rows containing species1\n                bestX_pattern = '|'.join(bestX)\n                rel_pairs['in_bestX'] = rel_pairs['birds'].str.contains(bestX_pattern)     # rows True if bird2 in row is in bestX\n                rel_pairs_in10 = rel_pairs.loc[rel_pairs['in_bestX']]['birds'].to_list()   # list of pairs with bird2 in bestX\n                if rel_pairs_in10:\n                    rel_bird = rel_pairs_in10[0].rsplit(' ')            # keep first pair, split it\n                    rel_bird.remove(species1)                           # bird related to species1\n                    rel_bird = str(rel_bird)\n                    bird2_flag = 1\n                    species2 = rel_bird\n            \n            if score1 < 0.35:     # add 'nocall' label anyway\n                if multilabel and bird2_flag:                            # multi-birds label is inaccurate\n                    data['birds'].append({species1, species2, 'nocall'})\n                    cnt +=2\n                else:\n                    data['birds'].append({species1, 'nocall'})\n                    cnt += 1\n            else:\n                if multilabel and bird2_flag:\n                    data['birds'].append({species1, species2})\n                    cnt +=2\n                else:\n                    data['birds'].append({species1})\n                    cnt += 1\n        else:\n            data['birds'].append({'nocall'})\n        # Add the confidence score\n        data['score'].append( str(score1.item()) + ' ' + str(score2.item()) )\n\nprint('SOUNDSCAPE ANALYSIS DONE. FOUND {} BIRDS.'.format(cnt))","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:53:38.711238Z","iopub.execute_input":"2022-05-12T13:53:38.711564Z","iopub.status.idle":"2022-05-12T13:56:56.235753Z","shell.execute_reply.started":"2022-05-12T13:53:38.711528Z","shell.execute_reply":"2022-05-12T13:56:56.234743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sets to strings\nprediction_dict = {'row_id' : [], 'birds' : []}\nfor row in data['row_id']:\n    prediction_dict['row_id'].append(row)\n\nfor row in data['birds']:\n    prediction_dict['birds'].append(' '.join(row))","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:56:56.238485Z","iopub.execute_input":"2022-05-12T13:56:56.239013Z","iopub.status.idle":"2022-05-12T13:56:56.247953Z","shell.execute_reply.started":"2022-05-12T13:56:56.23897Z","shell.execute_reply":"2022-05-12T13:56:56.246839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create submission file\nsubmission = pd.DataFrame(prediction_dict, columns = ['row_id', 'birds'])\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:56:56.249218Z","iopub.execute_input":"2022-05-12T13:56:56.249607Z","iopub.status.idle":"2022-05-12T13:56:56.271746Z","shell.execute_reply.started":"2022-05-12T13:56:56.249577Z","shell.execute_reply":"2022-05-12T13:56:56.270139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:56:56.274006Z","iopub.execute_input":"2022-05-12T13:56:56.27453Z","iopub.status.idle":"2022-05-12T13:56:56.286457Z","shell.execute_reply.started":"2022-05-12T13:56:56.274497Z","shell.execute_reply":"2022-05-12T13:56:56.285704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame(data, columns = ['row_id', 'birds', 'score'])       # new dataframe\nresults.rename(columns = {'birds':'prediction'}, inplace = True)\nresults = pd.merge(truth, results, on='row_id')                            # merge with true labels\n\n# Let's look at some entries\nresults[1050:1100]","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:16:21.793316Z","iopub.execute_input":"2022-05-12T13:16:21.794517Z","iopub.status.idle":"2022-05-12T13:16:21.85019Z","shell.execute_reply.started":"2022-05-12T13:16:21.79447Z","shell.execute_reply":"2022-05-12T13:16:21.849047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_species_nocall = np.append('nocall', all_species)\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer(classes = all_species_nocall)\n\ny_prediction = list(results['prediction'])\ny_pred_matrix = mlb.fit_transform(y_prediction)\n\n# true birds list to list of sets\ny_truth = []\nfor element in list(results['birds']):\n    y_truth.append(set(element.split()))\ny_true_matrix = mlb.fit_transform(y_truth)\n\nf1 = f1_score(y_true_matrix, y_pred_matrix, average='micro')\nprint('F1 = %.3f' %(f1))\n\nf1_398 = f1_score(y_true_matrix, y_pred_matrix, average=None)            # f1 for each class\nprint('\\n', 'F1_classes:\\n', f1_398)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:16:21.85155Z","iopub.execute_input":"2022-05-12T13:16:21.85177Z","iopub.status.idle":"2022-05-12T13:16:22.058107Z","shell.execute_reply.started":"2022-05-12T13:16:21.851743Z","shell.execute_reply":"2022-05-12T13:16:22.056878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.rmtree('./TEST_SOUNDSCAPES_MEL_DATASET')","metadata":{"execution":{"iopub.status.busy":"2022-05-12T13:16:22.059615Z","iopub.execute_input":"2022-05-12T13:16:22.060295Z","iopub.status.idle":"2022-05-12T13:16:22.147056Z","shell.execute_reply.started":"2022-05-12T13:16:22.060255Z","shell.execute_reply":"2022-05-12T13:16:22.146088Z"},"trusted":true},"execution_count":null,"outputs":[]}]}