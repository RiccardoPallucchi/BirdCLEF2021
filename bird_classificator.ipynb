{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm.notebook import tqdm, trange\nimport os\nfrom typing import Mapping, Union, Optional, Callable, Dict\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import Dataset, Subset, DataLoader, SubsetRandomSampler, TensorDataset, ConcatDataset\nimport warnings\nwarnings.filterwarnings(action='ignore')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:47:51.141112Z","iopub.execute_input":"2022-05-16T16:47:51.141984Z","iopub.status.idle":"2022-05-16T16:47:52.902268Z","shell.execute_reply.started":"2022-05-16T16:47:51.141881Z","shell.execute_reply":"2022-05-16T16:47:52.901463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset and data distribution","metadata":{}},{"cell_type":"code","source":"SAMPLING_RATE = 32000 # Hertz\nINPUT_LENGTH = 5      # seconds\nSPEC_SHAPE = (48,128) # spectrogram shape\nFMIN=500              # Hz (~min frequency for birds)\nFMAX=12500            # Hz (~max frequency for birds)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:47:52.904223Z","iopub.execute_input":"2022-05-16T16:47:52.905359Z","iopub.status.idle":"2022-05-16T16:47:52.910247Z","shell.execute_reply.started":"2022-05-16T16:47:52.905293Z","shell.execute_reply":"2022-05-16T16:47:52.909382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset_path = \"./dataset\"\nzip_path = \"../input/bird-dataset-20s/melspec_dataset_20s.zip\"\nDATA_MEAN = 0.3674\nDATA_STD = 0.1928\nimport zipfile\nwith zipfile.ZipFile(zip_path, 'r') as zip_ref:\n    zip_ref.extractall(train_dataset_path)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:47:52.911612Z","iopub.execute_input":"2022-05-16T16:47:52.912337Z","iopub.status.idle":"2022-05-16T16:49:01.978697Z","shell.execute_reply.started":"2022-05-16T16:47:52.912275Z","shell.execute_reply":"2022-05-16T16:49:01.977441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AddGaussianNoise(object):\n    def __init__(self, mean=0., std=1.):\n        self.std = std\n        self.mean = mean\n        \n    def __call__(self, tensor):\n        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n    \n    def __repr__(self):\n        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n\nclass TimeRecombination(object):\n    def __init__(self, partition):\n        self.partition = partition\n    \n    def __call__(self, tensor):\n        if tensor.shape[-1] == 256:              # 10 seconds\n            if self.partition == 0:\n                pieces_width = [100,50,50,56]\n            if self.partition == 1:\n                pieces_width = [50,40,40,30,30,30,36]\n        if tensor.shape[-1] == 512:              # 20 seconds\n            if self.partition == 0:\n                pieces_width = [100,100,100,50,50,56,56]\n            if self.partition == 1:\n                pieces_width = [35,35,30,40,40,40,40,30,30,30,30,30,30,36,36]\n        if tensor.shape[-1] == 768:              # 30 seconds\n            if self.partition == 0:\n                pieces_width = [100,100,100,50,50,50,50,50,50,56,56,56]\n            if self.partition == 1:\n                pieces_width = [50,50,50,40,40,40,40,40,40,30,30,30,30,30,30,30,30,30,36,36,36]\n        random.shuffle(pieces_width)\n        tensor = torch.split(tensor, pieces_width, dim = -1)\n        return torch.cat(random.sample(tensor,len(pieces_width)), dim= -1)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:01.982393Z","iopub.execute_input":"2022-05-16T16:49:01.982763Z","iopub.status.idle":"2022-05-16T16:49:02.000786Z","shell.execute_reply.started":"2022-05-16T16:49:01.982719Z","shell.execute_reply":"2022-05-16T16:49:01.999826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchaudio.transforms as audiotransf\n\ntransform =  transforms.Compose([transforms.Grayscale(), \n                                 transforms.ToTensor(), \n                                 transforms.Normalize(mean=DATA_MEAN, std=DATA_STD),\n                                 AddGaussianNoise(0., 0.2),\n                                 audiotransf.TimeMasking(time_mask_param = 150, iid_masks = True),   # MODIFY with size\n                                 audiotransf.FrequencyMasking(freq_mask_param = 5, iid_masks = True),\n                                 TimeRecombination(partition = 1)\n                                ])\ndataset = datasets.ImageFolder(root= train_dataset_path, transform=transform)\nlen(dataset), len(dataset.classes)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-16T16:49:02.002672Z","iopub.execute_input":"2022-05-16T16:49:02.002987Z","iopub.status.idle":"2022-05-16T16:49:03.216981Z","shell.execute_reply.started":"2022-05-16T16:49:02.002947Z","shell.execute_reply":"2022-05-16T16:49:03.216249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx_to_class = {v:k for k,v in dataset.class_to_idx.items()}\n# dataset.class_to_idx             # lists all classes","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:03.219201Z","iopub.execute_input":"2022-05-16T16:49:03.219551Z","iopub.status.idle":"2022-05-16T16:49:03.224453Z","shell.execute_reply.started":"2022-05-16T16:49:03.219506Z","shell.execute_reply":"2022-05-16T16:49:03.223529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset example\nimport plotly.express as px\n\ntraining_index = random.randint(0, len(dataset))\nimage, label = dataset[training_index]    # image.shape = torch.Size([1, 48, 128])\n\nexample = np.array(image[0])              # 48x128\n\nfig = px.imshow(example, \n                title=idx_to_class[int(label)],\n                color_continuous_scale='gray', \n                color_continuous_midpoint=0,\n                labels = dict(x = 'Time (s)',y = 'Frequency (Hz)'),\n               )\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:03.226178Z","iopub.execute_input":"2022-05-16T16:49:03.22692Z","iopub.status.idle":"2022-05-16T16:49:06.455714Z","shell.execute_reply.started":"2022-05-16T16:49:03.226879Z","shell.execute_reply":"2022-05-16T16:49:06.45471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metadata","metadata":{}},{"cell_type":"code","source":"# Load metadata file\nmetadata_df = pd.read_csv('../input/birdclef-2021/train_metadata.csv')\nall_species = metadata_df['primary_label'].unique()\nmeta_df = metadata_df[[\"filename\",\"primary_label\",\"latitude\",\"longitude\",\"date\",\"time\",\"rating\"]]  # retain\n# TIME OF DAY NOT PRESENT ON TEST DATA: USELESS\nmeta_df","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:06.457397Z","iopub.execute_input":"2022-05-16T16:49:06.45788Z","iopub.status.idle":"2022-05-16T16:49:07.1088Z","shell.execute_reply.started":"2022-05-16T16:49:06.457845Z","shell.execute_reply":"2022-05-16T16:49:07.107872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.mode.chained_assignment = None  # default='warn'\n\n# express DATE in days (remove year)\ndef date_transform(date):\n    return int(date.rsplit('-')[2]) + max(0, int(date.rsplit('-')[1])-1)*30\nmeta_df['date'] = meta_df['date'].apply(date_transform)\n\n# express TIME in minutes\ndef time_transform(time):\n   # exclude '?', 'xx', 'xx:xx', 'night', 'am'\n    if not(any(map(str.isdigit, time))):     # if no numbers inside\n        return np.random.randint(0,1440)     # method1: in this way we will not increase a specific time slot\n    else:\n        Q = 0\n        time = time.lower()                  # AM,PM->am,pm\n        if 'pm' in time:\n            Q = 1\n        time = time.replace('pm','')\n        time = time.replace('am','')\n        time = time.rsplit(':')\n        minutes = 0\n        if len(time)>1:\n            minutes = int(time[1])\n        result = (int(time[0]) + Q*12)*60 + minutes\n        return( result%1440 )                # there are also '12:30pm', '12:15pm', '24:15', etc\nmeta_df['time'] = meta_df['time'].apply(time_transform)\nmeta_df","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:07.110333Z","iopub.execute_input":"2022-05-16T16:49:07.111019Z","iopub.status.idle":"2022-05-16T16:49:07.456835Z","shell.execute_reply.started":"2022-05-16T16:49:07.11098Z","shell.execute_reply":"2022-05-16T16:49:07.455824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = plt.hist(meta_df['time'], 100)\nplt.show\n# suspicious peak at t=0; remove?","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:07.460676Z","iopub.execute_input":"2022-05-16T16:49:07.460906Z","iopub.status.idle":"2022-05-16T16:49:07.88708Z","shell.execute_reply.started":"2022-05-16T16:49:07.460879Z","shell.execute_reply":"2022-05-16T16:49:07.886255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NORMALIZE METADATA\nMETA_MEAN = []\nMETA_STD = []\nfor col in ['latitude', 'longitude', 'date', 'time']:\n    mean_col = meta_df[col].mean()\n    std_col = meta_df[col].std()\n    META_MEAN.append(mean_col)\n    META_STD.append(std_col)\n    meta_df[col] = ( meta_df[col] - mean_col) / std_col\nmeta_df","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:07.888428Z","iopub.execute_input":"2022-05-16T16:49:07.889265Z","iopub.status.idle":"2022-05-16T16:49:07.919154Z","shell.execute_reply.started":"2022-05-16T16:49:07.889222Z","shell.execute_reply":"2022-05-16T16:49:07.918414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# repeat each row in meta_df 'duration' times:\nduration_df = pd.read_csv('../input/bird-dataset-20s/duration.csv', header=None)  # inport duration (n*5 seconds)\nduration_df = duration_df[0]\n\n# DEPENDS ON DATASET!\n\n# 0) first5s\n# # meta_df is left unchanged\n\n# 1) whole dataset\n# meta_df = meta_df.loc[meta_df.index.repeat(duration_df)]\n\n# 2) dataset: rating >=4\n# duration_df = duration_df.loc[meta_df.query('rating>=4').index]\n# meta_df = meta_df.query('rating>=4')\n# meta_df = meta_df.loc[meta_df.index.repeat(duration_df)]\n\n# 3) first_last5s\n# meta_df = meta_df.loc[meta_df.index.repeat(2)]\n\n# 4) 10 seconds\n# meta_df = meta_df.loc[duration_df.loc[duration_df>=2].index]   # 5*2=10\n# duration_df = duration_df.loc[duration_df>=2]     # shape= \n# meta_df = meta_df.loc[meta_df.index.repeat(duration_df/2)]\n\n# 5) 20 seconds\nmeta_df = meta_df.loc[duration_df.loc[duration_df>=4].index]     # 5*4=20\nduration_df = duration_df.loc[duration_df>=4]                    # shape= 45278\nmeta_df = meta_df.loc[meta_df.index.repeat(duration_df/4)]\n\n# 6) 30 seconds\n# meta_df = meta_df.loc[duration_df.loc[duration_df>=6].index]   # 5*6=30\n# duration_df = duration_df.loc[duration_df>=6]                  # shape= 45278\n# meta_df = meta_df.loc[meta_df.index.repeat(duration_df/6)]","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:07.920294Z","iopub.execute_input":"2022-05-16T16:49:07.921123Z","iopub.status.idle":"2022-05-16T16:49:07.974861Z","shell.execute_reply.started":"2022-05-16T16:49:07.921089Z","shell.execute_reply":"2022-05-16T16:49:07.974118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get meta_tensor\nmeta_tensor = torch.tensor([meta_df['latitude'].values, meta_df['longitude'].values, meta_df['date'].values]).float()\nmeta_tensor = torch.transpose(meta_tensor, 0, 1)\nmeta_tensor.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:07.975869Z","iopub.execute_input":"2022-05-16T16:49:07.976535Z","iopub.status.idle":"2022-05-16T16:49:08.060103Z","shell.execute_reply.started":"2022-05-16T16:49:07.976476Z","shell.execute_reply":"2022-05-16T16:49:08.059497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create meta_dataset\nmeta_dataset = TensorDataset(meta_tensor)   # dataset without targets\nlen(meta_dataset) == len(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.061586Z","iopub.execute_input":"2022-05-16T16:49:08.06253Z","iopub.status.idle":"2022-05-16T16:49:08.069545Z","shell.execute_reply.started":"2022-05-16T16:49:08.062482Z","shell.execute_reply":"2022-05-16T16:49:08.068625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Filtered data, train and validation sets","metadata":{}},{"cell_type":"code","source":"# loader = DataLoader(dataset, batch_size=1024, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.07109Z","iopub.execute_input":"2022-05-16T16:49:08.072014Z","iopub.status.idle":"2022-05-16T16:49:08.080692Z","shell.execute_reply.started":"2022-05-16T16:49:08.07197Z","shell.execute_reply":"2022-05-16T16:49:08.080089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # filter data:\n# # compute pixels mean on each row (avg pool on 128-pixel wide rectangles)\n# # compute pixels sum on fixed size rectangles, then compare to mean (avg pool on smaller rectangles)\n\n# from torch.nn import AvgPool2d\n\n# Patch_averager = AvgPool2d(kernel_size =(8,7))         # filter1\n# # Col_averager = AvgPool2d(kernel_size =(6,128*4))       # filter2\n# # Patch_averager = AvgPool2d(kernel_size =(6,4))         # filter2\n\n# good_array = np.array([]).astype(int)\n# species_good_cnt = np.zeros(len(dataset.classes))\n\n# tqdm_iterator = tqdm(\n#     enumerate(loader),\n#     total=len(loader),\n#     leave=False,\n# )\n# batch_size = 1024\n# for batch_idx, (data,target) in tqdm_iterator:\n\n#     # filter1\n#     AvgPatches = Patch_averager(data[:,:,:,:-2])\n#     diff = torch.diff(AvgPatches, dim=3)\n#     diff = diff.view(diff.shape[0], -1)\n#     # select indices in each batch:\n#     inner_idx_good = np.where(np.any(np.absolute(np.array(diff))>0.58,axis=1))[0].astype(int)\n\n# #     # filter2\n# #     AvgCol = Col_averager(data)         # 64x1x12\n# #     AvgPatches = Patch_averager(data)\n# #     diff = AvgPatches - AvgCol          # 64x1x12x32\n# #     diff = diff.view(diff.shape[0], -1) # 64x(12*32)\n# #     # select indices in each batch:\n# #     inner_idx_good = np.where(np.any(np.array(diff)>0.63,axis=1))[0].astype(int)\n# #     inner_idx_good = inner_idx_good[np.array(species_good_cnt[np.array(target.reshape(-1)[torch.tensor(inner_idx_good)])] < 4000)] \n    \n#     # count species for each group\n#     a1, b1 = np.unique(target[np.array(inner_idx_good)], return_counts = True)\n#     species_good_cnt[a1] += b1\n#     # create list for the entire dataset\n#     good_indices = batch_idx*batch_size + inner_idx_good\n#     good_array = np.append(good_array, good_indices)\n\n# len(good_array)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.082175Z","iopub.execute_input":"2022-05-16T16:49:08.082698Z","iopub.status.idle":"2022-05-16T16:49:08.095194Z","shell.execute_reply.started":"2022-05-16T16:49:08.082655Z","shell.execute_reply":"2022-05-16T16:49:08.094516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # good/all ratio\n\n# all_birds = meta_df['primary_label'].value_counts(sort=False)\n# all_birds, species_good_cnt/all_birds,","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.096733Z","iopub.execute_input":"2022-05-16T16:49:08.097256Z","iopub.status.idle":"2022-05-16T16:49:08.111659Z","shell.execute_reply.started":"2022-05-16T16:49:08.097168Z","shell.execute_reply":"2022-05-16T16:49:08.110945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# thrown_away = all_birds - species_good_cnt\n# plt.plot(list(range(len(dataset.classes))), species_good_cnt)\n# plt.plot(list(range(len(dataset.classes))), thrown_away)\n# plt.legend(['selected birds (tot {})' .format(species_good_cnt.sum()), \n#             'thrown away (tot {})' .format(thrown_away.sum())])\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.113203Z","iopub.execute_input":"2022-05-16T16:49:08.11373Z","iopub.status.idle":"2022-05-16T16:49:08.125395Z","shell.execute_reply.started":"2022-05-16T16:49:08.113663Z","shell.execute_reply":"2022-05-16T16:49:08.124719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# thrown_away = all_birds - species_good_cnt\n# plt.plot(list(range(len(dataset.classes))), species_good_cnt/all_birds)\n# plt.plot(list(range(len(dataset.classes))), thrown_away/all_birds)\n# plt.legend(['% selected birds', '% thrown away'])\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.127372Z","iopub.execute_input":"2022-05-16T16:49:08.127915Z","iopub.status.idle":"2022-05-16T16:49:08.142579Z","shell.execute_reply.started":"2022-05-16T16:49:08.12787Z","shell.execute_reply":"2022-05-16T16:49:08.141886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# good_list = good_array.tolist()\n\n# import csv\n# with open('good_list4.1_1.8.csv', 'w') as f:\n#     writer = csv.writer(f)\n#     writer.writerow(list(range(len(good_list))))\n#     writer.writerow(good_list)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.143923Z","iopub.execute_input":"2022-05-16T16:49:08.144689Z","iopub.status.idle":"2022-05-16T16:49:08.155055Z","shell.execute_reply.started":"2022-05-16T16:49:08.144633Z","shell.execute_reply":"2022-05-16T16:49:08.154062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # good_list from file:\n# good_df = pd.read_csv('../input/good-list/good_list4.1_1.5.csv')\n# good_list = good_df.values.tolist()[0]\n\n# len(good_list)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.156201Z","iopub.execute_input":"2022-05-16T16:49:08.156447Z","iopub.status.idle":"2022-05-16T16:49:08.167514Z","shell.execute_reply.started":"2022-05-16T16:49:08.15642Z","shell.execute_reply":"2022-05-16T16:49:08.166507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered = 0              # all data\n# filtered = 1              # filtered data\n# filtered = 2              # random data, len = len(good_list)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.168506Z","iopub.execute_input":"2022-05-16T16:49:08.168916Z","iopub.status.idle":"2022-05-16T16:49:08.179477Z","shell.execute_reply.started":"2022-05-16T16:49:08.168883Z","shell.execute_reply":"2022-05-16T16:49:08.178654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(0)\ntorch.manual_seed(0)\n\nval_split_ratio = 0.2\n\nif filtered == 0:\n    VAL_TOT = int(np.floor(len(dataset)*val_split_ratio))\n    dataset_indices = list(range(len(dataset)))\n    np.random.shuffle(dataset_indices)\n    split_index = int(np.floor(val_split_ratio*len(dataset)))\nelif filtered == 1:\n    VAL_TOT = int(np.floor(len(good_list)*val_split_ratio))\n    dataset_indices = good_list\n    np.random.shuffle(dataset_indices)\n    split_index = int(np.floor(val_split_ratio*len(good_list)))\nelif filtered == 2:           # RANDOM SAMPLES, same lenght as good_list\n    VAL_TOT = int(np.floor(len(good_list)*val_split_ratio))\n    dataset_indices = list(np.random.randint(low=0, high = len(dataset), size = len(good_list)))\n    np.random.shuffle(dataset_indices)\n    split_index = int(np.floor(val_split_ratio*len(good_list)))\n\ntrain_idx, val_idx = dataset_indices[split_index:], dataset_indices[:split_index]","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.180516Z","iopub.execute_input":"2022-05-16T16:49:08.181293Z","iopub.status.idle":"2022-05-16T16:49:08.218886Z","shell.execute_reply.started":"2022-05-16T16:49:08.181248Z","shell.execute_reply":"2022-05-16T16:49:08.218226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sampler = SubsetRandomSampler(train_idx)\nval_sampler = SubsetRandomSampler(val_idx)\n\ntrain_loader = DataLoader(dataset, batch_size=64, shuffle = False, sampler = train_sampler)\nmeta_train_loader = DataLoader(meta_dataset, batch_size=64, shuffle = False, sampler = train_sampler)\nval_loader = DataLoader(dataset, batch_size=64, shuffle = False, sampler = val_sampler)\nmeta_val_loader = DataLoader(meta_dataset, batch_size=64, shuffle = False, sampler = val_sampler)\n\nprint(\"Batch data shape (train_loader):  \", next(iter(train_loader))[0].shape)\nprint(\"Number of batches (train_loader):  \", len(train_loader))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.219896Z","iopub.execute_input":"2022-05-16T16:49:08.22082Z","iopub.status.idle":"2022-05-16T16:49:08.877042Z","shell.execute_reply.started":"2022-05-16T16:49:08.220769Z","shell.execute_reply":"2022-05-16T16:49:08.876126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # plotlib error =>\n# from plotly.offline import plot, iplot, init_notebook_mode\n# init_notebook_mode(connected=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.880112Z","iopub.execute_input":"2022-05-16T16:49:08.880364Z","iopub.status.idle":"2022-05-16T16:49:08.884365Z","shell.execute_reply.started":"2022-05-16T16:49:08.88033Z","shell.execute_reply":"2022-05-16T16:49:08.883357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The model","metadata":{}},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, input_size: int, input_channels: int, n_feature1: int, n_feature2: int, n_feature3: int, \n                 n_feature4: int, n_feature5: int, outputs: int) -> None:\n        super().__init__()\n        \n        self.n_feature1 = n_feature1\n        self.conv1 = nn.Conv2d(input_channels, n_feature1, kernel_size=3, padding = 'same')\n        self.conv2 = nn.Conv2d(n_feature1, n_feature2, kernel_size=3, padding = 'same')\n        self.conv3 = nn.Conv2d(n_feature2, n_feature3, kernel_size=3, padding = 'same')\n        self.conv4 = nn.Conv2d(n_feature3, n_feature4, kernel_size=3, padding = 'same')\n        self.conv5 = nn.Conv2d(n_feature4, n_feature5, kernel_size=3, padding = 'same')\n        \n        self.pool = nn.MaxPool2d(2,2)\n        \n        self.bn1 = nn.BatchNorm2d(n_feature1)\n        self.bn2 = nn.BatchNorm2d(n_feature2)\n        self.bn3 = nn.BatchNorm2d(n_feature3)\n        self.bn4 = nn.BatchNorm2d(n_feature4)\n        self.bn5 = nn.BatchNorm2d(n_feature5)\n        self.bnf1 = nn.BatchNorm1d(2048)        # modify along with fc dimensions\n\n        self.drop2d = nn.Dropout2d(p=0.2)\n        self.drop = nn.Dropout(p=0.4)\n                \n        self.meta_rep = 32\n        \n        self.fc1 = nn.Linear(n_feature5 * 1*16, 2048)          # 128(5s)->256(10s)->512(20s)->768(30s) => 4->8->16->24\n        self.fc2 = nn.Linear(2048 + self.meta_rep*3, outputs)\n\n    def forward(self, x: list) -> torch.Tensor:\n        \n        D = x[0]  # data\n        M = x[1]  # meta\n        Lat = M[:,0].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        Lon = M[:,1].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        Date = M[:,2].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        \n#         #APPLY MASK\n#         thresh = 0.5\n#         Col_averager = AvgPool2d(kernel_size =(1,128))\n#         condition = (D - Col_averager(D)) < thresh\n#         D[condition] = 0\n        \n        #print(x.shape)                                               # torch.Size([64, 1, 48, 768] 512] 256] 128])\n        D = self.drop2d(self.pool(self.bn1(F.relu(self.conv1(D))))) # [64, n_feature1, 24, 384] 256] 128] 64]\n        D = self.drop2d(self.pool(self.bn2(F.relu(self.conv2(D))))) # [64, n_feature2, 12, 192] 128] 64] 32]\n        D = self.drop2d(self.pool(self.bn3(F.relu(self.conv3(D))))) # [64, n_feature3, 6, 96] 64] 32] 16]\n        D = self.drop2d(self.pool(self.bn4(F.relu(self.conv4(D))))) # [64, n_feature4, 3, 48] 32] 16] 8]\n        D = self.drop2d(self.pool(self.bn5(F.relu(self.conv5(D))))) # [64, n_feature5, 1, 24] 16] 8] 4]\n        \n        \n        D = D.view(D.shape[0], -1)        \n        D = self.drop(self.bnf1(F.relu(self.fc1(D))))\n        \n        # ADD METADATA\n        D = torch.cat((D, Lat, Lon, Date),1)    # data & meta\n        \n        D = self.fc2(D)\n        return D\n\n# identity + nn.CrossEntropyLoss = F.log_softmax + nn.NLLLoss","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.88589Z","iopub.execute_input":"2022-05-16T16:49:08.886197Z","iopub.status.idle":"2022-05-16T16:49:08.908911Z","shell.execute_reply.started":"2022-05-16T16:49:08.886158Z","shell.execute_reply":"2022-05-16T16:49:08.90785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# (ReLU BEFORE AND AFTER ADDITION) +dropout \nclass ResBlock1(nn.Module):\n    def __init__(self, in_channels, out_channels, downsample):\n        super().__init__()\n        if downsample:\n            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),\n                nn.BatchNorm2d(out_channels)\n            )\n        else:\n            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n            self.shortcut = nn.Sequential()\n\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.drop2d = nn.Dropout2d(p=0.1)\n\n    def forward(self, input):\n        shortcut = self.shortcut(input)\n        \n        input = nn.ReLU()(self.bn1(self.conv1(input)))          # pool substituted with stride\n        input = self.drop2d(input)\n        input = nn.ReLU()(self.bn2(self.conv2(input)))\n        input = input + shortcut\n        return nn.ReLU()(input)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.910293Z","iopub.execute_input":"2022-05-16T16:49:08.910549Z","iopub.status.idle":"2022-05-16T16:49:08.926929Z","shell.execute_reply.started":"2022-05-16T16:49:08.91052Z","shell.execute_reply":"2022-05-16T16:49:08.925952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ResNet34 first version\nclass ResNet34(nn.Module):\n    def __init__(self, in_channels, resblock, outputs=397):\n        super().__init__()\n        self.layer0 = nn.Sequential(\n            nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU()\n        )\n\n        self.layer1 = nn.Sequential(\n            resblock(64, 64, downsample=False),\n            resblock(64, 64, downsample=False),\n            resblock(64, 64, downsample=False)\n        )\n\n        self.layer2 = nn.Sequential(\n            resblock(64, 128, downsample=True),\n            resblock(128, 128, downsample=False),\n            resblock(128, 128, downsample=False),\n            resblock(128, 128, downsample=False)\n        )\n\n        self.layer3 = nn.Sequential(\n            resblock(128, 256, downsample=True),\n            resblock(256, 256, downsample=False),\n            resblock(256, 256, downsample=False),\n            resblock(256, 256, downsample=False),\n            resblock(256, 256, downsample=False),\n            resblock(256, 256, downsample=False)\n        )\n\n\n        self.layer4 = nn.Sequential(\n            resblock(256, 512, downsample=True),\n            resblock(512, 512, downsample=False),\n            resblock(512, 512, downsample=False),\n        )\n\n        self.meta_rep = 64\n        self.gap = torch.nn.AdaptiveAvgPool2d(1)        \n        self.fc = torch.nn.Linear(512 + self.meta_rep*3, outputs)\n        self.drop = nn.Dropout(p=0.4)\n\n    def forward(self, input):\n        \n        D = input[0]  # data\n        M = input[1]  # meta\n        Lat = M[:,0].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        Lon = M[:,1].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        Date = M[:,2].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        \n        D = self.layer0(D)\n        D = self.layer1(D)\n        D = self.layer2(D)\n        D = self.layer3(D)\n        D = self.layer4(D)\n        D = self.gap(D)                # [64, feature_maps, h, w] -> [64, feature_maps, 1]\n\n        D = D.view(D.shape[0], -1)     # [64, feature_maps, 1]    ->  [64, feature_maps]\n        D = self.drop(D)   \n        DM = torch.cat((D, Lat, Lon, Date),1)    # data & meta\n        \n        DM = self.fc(DM)\n\n        return DM","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.930937Z","iopub.execute_input":"2022-05-16T16:49:08.931716Z","iopub.status.idle":"2022-05-16T16:49:08.954091Z","shell.execute_reply.started":"2022-05-16T16:49:08.931675Z","shell.execute_reply":"2022-05-16T16:49:08.95336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResBottleneckBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, downsample):\n        super().__init__()\n        self.downsample = downsample\n        self.conv1 = nn.Conv2d(in_channels, out_channels//4, kernel_size=1, stride=1)\n        self.conv2 = nn.Conv2d(out_channels//4, out_channels//4, kernel_size=3, stride=2 if downsample else 1, padding=1)\n        self.conv3 = nn.Conv2d(out_channels//4, out_channels, kernel_size=1, stride=1)\n        self.shortcut = nn.Sequential()\n        \n        if self.downsample or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2 if self.downsample else 1),\n                nn.BatchNorm2d(out_channels)\n            )\n\n        self.bn1 = nn.BatchNorm2d(out_channels//4)\n        self.bn2 = nn.BatchNorm2d(out_channels//4)\n        self.bn3 = nn.BatchNorm2d(out_channels)\n        \n        self.drop2d = nn.Dropout2d(p=0.2)      # batchnorm alone leads to overfitting\n\n    def forward(self, input):\n        shortcut = self.shortcut(input)\n        input = nn.ReLU()(self.bn1(self.conv1(input)))\n        input = self.drop2d(input)\n        input = nn.ReLU()(self.bn2(self.conv2(input)))\n        input = self.drop2d(input)\n        input = nn.ReLU()(self.bn3(self.conv3(input)))\n        input = input + shortcut\n        return nn.ReLU()(input)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.955413Z","iopub.execute_input":"2022-05-16T16:49:08.956329Z","iopub.status.idle":"2022-05-16T16:49:08.973326Z","shell.execute_reply.started":"2022-05-16T16:49:08.956264Z","shell.execute_reply":"2022-05-16T16:49:08.972684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNet(nn.Module):\n    def __init__(self, in_channels, resblock, repeat, useBottleneck=False, outputs=397):\n        super().__init__()\n        self.layer0 = nn.Sequential(\n            nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU()\n        )\n\n        if useBottleneck:\n            filters = [64, 256, 512, 1024, 2048]\n            self.meta_rep = 128\n        else:\n            filters = [64, 64, 128, 256, 512]\n            self.meta_rep = 64\n\n        self.layer1 = nn.Sequential()\n        self.layer1.add_module('conv2_1', resblock(filters[0], filters[1], downsample=False))\n        for i in range(1, repeat[0]):\n                self.layer1.add_module('conv2_%d'%(i+1,), resblock(filters[1], filters[1], downsample=False))\n\n        self.layer2 = nn.Sequential()\n        self.layer2.add_module('conv3_1', resblock(filters[1], filters[2], downsample=True))\n        for i in range(1, repeat[1]):\n                self.layer2.add_module('conv3_%d' % (i+1,), resblock(filters[2], filters[2], downsample=False))\n\n        self.layer3 = nn.Sequential()\n        self.layer3.add_module('conv4_1', resblock(filters[2], filters[3], downsample=True))\n        for i in range(1, repeat[2]):\n            self.layer3.add_module('conv2_%d' % (i+1,), resblock(filters[3], filters[3], downsample=False))\n\n        self.layer4 = nn.Sequential()\n        self.layer4.add_module('conv5_1', resblock(filters[3], filters[4], downsample=True))\n        for i in range(1, repeat[3]):\n            self.layer4.add_module('conv3_%d'%(i+1,), resblock(filters[4], filters[4], downsample=False))\n\n        self.gap = torch.nn.AdaptiveAvgPool2d(1)\n        self.fc = torch.nn.Linear(filters[4] + self.meta_rep*3, outputs)\n        self.drop = nn.Dropout(p=0.4)\n\n    def forward(self, input):\n        \n        D = input[0]  # data\n        M = input[1]  # meta\n        Lat = M[:,0].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        Lon = M[:,1].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        Date = M[:,2].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        \n        D = self.layer0(D)\n        D = self.layer1(D)\n        D = self.layer2(D)\n        D = self.layer3(D)\n        D = self.layer4(D)\n        D = self.gap(D)                # [64, feature_maps, h, w] -> [64, feature_maps, 1]\n        \n        D = D.view(D.shape[0], -1)     # [64, feature_maps, 1, 1]    ->  [64, feature_maps]\n        D = self.drop(D)\n        \n        DM = torch.cat((D, Lat, Lon, Date),1)    # data & meta\n        \n        DM = self.fc(DM)\n\n        return DM","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:08.974908Z","iopub.execute_input":"2022-05-16T16:49:08.975543Z","iopub.status.idle":"2022-05-16T16:49:08.999861Z","shell.execute_reply.started":"2022-05-16T16:49:08.9755Z","shell.execute_reply":"2022-05-16T16:49:08.998811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x, _ = next(iter(train_loader))\ninput_size_w, input_size_h = x.shape[2], x.shape[3]\ninput_size = input_size_w * input_size_h\n\n# Define the device to use\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f'Using device: {device}') ","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:09.001424Z","iopub.execute_input":"2022-05-16T16:49:09.001835Z","iopub.status.idle":"2022-05-16T16:49:09.282861Z","shell.execute_reply.started":"2022-05-16T16:49:09.00179Z","shell.execute_reply":"2022-05-16T16:49:09.28197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CNN\nconvnet5 = CNN(input_size, input_channels=1, n_feature1=32, n_feature2=64, n_feature3=128, n_feature4=256, n_feature5=512, outputs=397)\n\n# resnet18\nresnet18 = ResNet(1, ResBlock1, [2, 2, 2, 2], useBottleneck=False, outputs=397)\n\n# resnet34\nresnet34 = ResNet(1, ResBlock1, [3, 4, 6, 3], useBottleneck=False, outputs=397)\n\n# resnet50\nresnet50 = ResNet(1, ResBottleneckBlock, [3, 4, 6, 3], useBottleneck=True, outputs=397)\n\n# resnet101\nresnet101 = ResNet(1, ResBottleneckBlock, [3, 4, 23, 3], useBottleneck=True, outputs=397)\n\n# resnet152\nresnet152 = ResNet(1, ResBottleneckBlock, [3, 8, 36, 3], useBottleneck=True, outputs=397)\n\nprint('Models initialization')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-16T16:49:09.284648Z","iopub.execute_input":"2022-05-16T16:49:09.284931Z","iopub.status.idle":"2022-05-16T16:49:11.442695Z","shell.execute_reply.started":"2022-05-16T16:49:09.284891Z","shell.execute_reply":"2022-05-16T16:49:11.441812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_averager() -> Callable[[Optional[float]], float]:\n    \"\"\" Returns a function that maintains a running average\n\n    :returns: running average function\n    \"\"\"\n    count = 0\n    total = 0\n\n    def averager(new_value: Optional[float]) -> float:\n        \"\"\" Running averager\n\n        :param new_value: number to add to the running average,\n                          if None returns the current average\n        :returns: the current average\n        \"\"\"\n        nonlocal count, total\n        if new_value is None:\n            return total / count if count else float(\"nan\")      # if count>0 => return total/count; if count=0 => return float('nan')\n        count += 1\n        total += new_value\n        return total / count\n\n    return averager\n\ndef test_model(\n    loss_func,\n    test_dl: torch.utils.data.DataLoader,\n    meta_test_dl: torch.utils.data.DataLoader,\n    model: torch.nn.Module,\n    device: str = \"cuda\"\n) -> Dict[str, Union[float, Callable[[Optional[float]], float]]]:\n    \n    model.eval()\n    test_loss_averager = make_averager()  # mantain a running average of the loss\n    correct = 0\n    with torch.no_grad():\n        for (data, target),meta in zip(test_dl, meta_test_dl):\n            # send to device\n            meta = meta[0]\n            data, target, meta = data.to(device), target.to(device), meta.to(device)\n            output = model([data, meta])\n    \n            test_loss_averager(loss_func(output, target).item())   # takes the average of the losses (cross_entropy) computed on all samples of the test set\n\n            # get the index of the max probability\n            pred = output.max(1, keepdim=True)[1]               # dim to reduce=1 (max along each row); keep dimension; [1] => indices of the maxima, [0] => maxima\n            correct += pred.eq(target.view_as(pred)).cpu().sum().item()  # \"a.eq(b)\" True if a=b; self.view_as(other) = self.view(other.size())\n\n    return {\n        \"accuracy\": 100.0 * correct / VAL_TOT,\n        \"loss_averager\": test_loss_averager,\n        \"correct\": correct,\n    }\n\ndef fit(\n    loss_func,\n    epochs: int,\n    train_dl: torch.utils.data.DataLoader,\n    meta_train_dl: torch.utils.data.DataLoader,\n    test_dl: torch.utils.data.DataLoader,\n    meta_test_dl: torch.utils.data.DataLoader,\n    model: torch.nn.Module,\n    opt: torch.optim.Optimizer,\n    device: str = \"cuda\"\n) -> float:\n    \n    for epoch in trange(epochs, desc=\"train epoch\"):    # \"trange\" adds a bar, \"desc\" adds a description\n        model.train()\n        train_loss_averager = make_averager()  # mantain a running average of the loss\n\n        # TRAIN\n        tqdm_iterator = tqdm(                      # adds a progress bar\n            enumerate(zip(train_dl,meta_train_dl)),\n            total=len(train_dl),\n            desc=f\"batch [loss: None]\",\n            leave=False,\n        )\n        for batch_idx, ((data,target), meta) in tqdm_iterator:\n            # send to device\n            meta = meta[0]\n            data, target, meta = data.to(device), target.to(device), meta.to(device)\n\n            opt.zero_grad()\n            output = model([data, meta])\n            loss = loss_func(output, target)\n            loss.backward()\n            opt.step()\n            \n            train_loss_averager(loss.item())\n            \n            tqdm_iterator.set_description(\n                f\"train batch [avg loss: {train_loss_averager(None):.3f}]\"\n            )\n            tqdm_iterator.refresh()\n        \n        scheduler.step()\n        # TEST\n        test_out = test_model(loss_func, test_dl, meta_test_dl, model,device)   # test_model outputs 'test_out' list\n\n        print(\n            f\"Epoch: {epoch}\\n\"\n            f\"Train set: Average loss: {train_loss_averager(None):.4f}\\n\"\n            f\"Val set: Average loss: {test_out['loss_averager'](None):.4f}, \"\n            f\"Accuracy: {test_out['correct']}/{VAL_TOT} \"\n            f\"({test_out['accuracy']:.1f}%)\\n\"\n        )\n        train_losses.append(train_loss_averager(None))\n        val_losses.append(test_out['loss_averager'](None))\n        accuracy.append(test_out['correct']/VAL_TOT)\n\n#     models_accuracy = test_out['accuracy']\n    return test_out['accuracy']      # final accuracy\n    \n# Just a function to count the number of parameters\ndef count_parameters(model: torch.nn.Module) -> int:\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:11.444212Z","iopub.execute_input":"2022-05-16T16:49:11.444458Z","iopub.status.idle":"2022-05-16T16:49:11.47001Z","shell.execute_reply.started":"2022-05-16T16:49:11.444429Z","shell.execute_reply":"2022-05-16T16:49:11.468813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\ndictionary = dict(Counter(dataset.targets))\nnumber_per_class = np.array(list(dictionary.values()))\nnumber_per_class.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:11.471605Z","iopub.execute_input":"2022-05-16T16:49:11.471828Z","iopub.status.idle":"2022-05-16T16:49:11.497058Z","shell.execute_reply.started":"2022-05-16T16:49:11.471802Z","shell.execute_reply":"2022-05-16T16:49:11.496032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 25\nfit_model = 0\nmodel = ResNet34(in_channels = 1, resblock = ResBlock1)\nmodel.to(device)\n\ntrain_losses, val_losses, accuracy = [], [], []\n# class_weights = 1 - number_per_class/len(dataset)\n# class_weights = torch.tensor(class_weights).to(torch.float32).to(device) # not beneficial on this model\n\noptimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.75)  # decays lr of each par. group by gamma every step_size epochs\nloss_func = nn.CrossEntropyLoss()#weight = class_weights)\nprint(f'Number of parameters: {count_parameters(model)}')\ntqdm._instances.clear()\n\nif fit_model:\n    fit(loss_func = loss_func,\n    epochs=epochs,\n    train_dl=train_loader,\n    meta_train_dl = meta_train_loader,\n    test_dl=val_loader,\n    meta_test_dl = meta_val_loader,\n    model=model,\n    opt=optimizer,\n    device=device)\n    \n    fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n    axs[0].set_title('Losses')\n    axs[0].plot(train_losses, label='Train loss')\n    axs[0].plot(val_losses, label='Val loss')\n    axs[0].legend()\n    axs[1].plot(accuracy)\n    axs[1].set_title('Accuracy')\n    for ax in axs.flat:\n        ax.set(xlabel='Epochs')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:11.498518Z","iopub.execute_input":"2022-05-16T16:49:11.49942Z","iopub.status.idle":"2022-05-16T16:49:11.811367Z","shell.execute_reply.started":"2022-05-16T16:49:11.499379Z","shell.execute_reply":"2022-05-16T16:49:11.810363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save = 0\nfrom datetime import datetime\nimport pytz\nif save:\n    timezone = pytz.timezone('Europe/Rome')\n    now = datetime.now(tz = timezone)\n    time_info = now.strftime(\"%d-%m--%H-%M\")\n    model_name = 'ResNet34_V2' + '.pt' #+ '_' + time_info \n    model_path = os.path.join('./', model_name)   # ./model_name.pt\n    torch.save(model.state_dict(), model_path)\n\n# os.remove(os.path.join(output_dir, 'model_cnn_200'))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:11.812538Z","iopub.execute_input":"2022-05-16T16:49:11.812841Z","iopub.status.idle":"2022-05-16T16:49:11.818967Z","shell.execute_reply.started":"2022-05-16T16:49:11.812809Z","shell.execute_reply":"2022-05-16T16:49:11.818013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.rmtree('./dataset')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:49:11.820521Z","iopub.execute_input":"2022-05-16T16:49:11.820838Z","iopub.status.idle":"2022-05-16T16:49:16.799328Z","shell.execute_reply.started":"2022-05-16T16:49:11.820798Z","shell.execute_reply":"2022-05-16T16:49:16.798288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Produced models scores and sets distribution:\n- ResNet34 on test set identifies 6.5% birds and 91% nocalls; on hidden kaggle set gives the highest F1 = 0.497\n- Resnet50 gives better results on test set (F1 = 0.57, identifies 10% birds and 91% nocalls) but on hidden kaggle set gives F1 = 0.485\n- Resnet50 with weighted crossentropy has hidden F1 = 0.492 (but the highest public F1 score); F1 = 0.494 with score1 thresh: species1 if >0.33, +nocall if <0.40","metadata":{}},{"cell_type":"markdown","source":"## Soundscapes","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load('../input/ResNet34/ResNet34.pt', map_location=torch.device('cpu')))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T16:50:02.241918Z","iopub.execute_input":"2022-05-16T16:50:02.242246Z","iopub.status.idle":"2022-05-16T16:50:02.331221Z","shell.execute_reply.started":"2022-05-16T16:50:02.24221Z","shell.execute_reply":"2022-05-16T16:50:02.330403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_TEST_landscape_spectrograms(audio_path, output_dir):\n    \n    sig, rate = librosa.load(audio_path, sr=SAMPLING_RATE, offset=None)\n    \n    lunp_samples = int(INPUT_LENGTH*SAMPLING_RATE)   # number of time samples in a 5s piece of signal (5s*32000Hz)\n    \n    # split signal into five second lumps\n    sig_splits = []\n    for i in range(0, len(sig), lunp_samples):\n        split = sig[i:i + lunp_samples]\n\n        # End of signal\n        if len(split) < lunp_samples:\n            break\n        sig_splits.append(split)\n    \n    # extract mel spectrograms\n    split_count = 0\n    samples = []\n    for lump in sig_splits:\n        \n        HOP_LENGTH = int((INPUT_LENGTH*SAMPLING_RATE)/(SPEC_SHAPE[1]-1))\n        mel_spec = librosa.feature.melspectrogram(y=lump,\n                                                 sr=SAMPLING_RATE,\n                                                 n_fft=1024,\n                                                 hop_length=HOP_LENGTH,\n                                                 n_mels=SPEC_SHAPE[0],\n                                                 fmin=FMIN,\n                                                 fmax=FMAX)\n        \n        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n    \n        # Normalize\n        mel_spec -= mel_spec.min()\n        mel_spec /= mel_spec.max()\n        \n        # Save as image file\n        # THIS TIME IN A SINGLE FOLDER (NO LABELS):\n        save_path = os.path.join(output_dir, audio_path.rsplit(os.sep, 1)[-1].rsplit('.', 1)[0].rsplit('_',1)[0] + \n                                 '_' + str((split_count+1)*5) + '.png')\n        \n        im = Image.fromarray(mel_spec * 255.0).convert(\"L\") # color -> greyscale (mode “L”): L = R * 299/1000 + G * 587/1000 + B * 114/1000\n        im.save(save_path)\n        \n        samples.append(save_path)\n        split_count += 1\n            \n    filename = audio_path.rsplit(os.sep, 1)[-1].rsplit('.', 1)[0]\n    location = filename.rsplit('_',2)[1]\n    meta_lat.append(geo_map[filename.rsplit('_',2)[1]][0])\n    meta_lon.append(geo_map[filename.rsplit('_',2)[1]][1])\n    date = filename.rsplit('_',1)[1][0:4] + '-' + filename.rsplit('_',1)[1][4:6] + '-' + filename.rsplit('_',1)[1][6:8]\n    meta_date.append(date_transform(date))\n    return samples","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:11:16.595988Z","iopub.execute_input":"2022-05-16T17:11:16.596828Z","iopub.status.idle":"2022-05-16T17:11:16.612393Z","shell.execute_reply.started":"2022-05-16T17:11:16.596783Z","shell.execute_reply":"2022-05-16T17:11:16.611532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EXTRACT TEST SPECTROGRAMS\n\nif not os.path.isdir('./TEST_SOUNDSCAPES_MEL_DATASET'):\n    !pip install natsort\n    import librosa\n    from natsort import natsorted\n\n    # os.rmdir('./TEST_SOUNDSCAPES_MEL_DATASET')\n\n    input_dir = '../input/birdclef-2021/train_soundscapes'\n    output_dir = './TEST_SOUNDSCAPES_MEL_DATASET'\n    os.makedirs(output_dir)\n    TEST_SPECS = []\n    geo_map = {'COL': [5.57,-75.85], 'COR':[10.12, -84.51], 'SNE':[38.49,-119.95], 'SSW':[42.47,-76.45]}\n    meta_lat = []\n    meta_lon = []\n    meta_date = []\n\n    # ORDER LIST OF FILENAMES according to train_soundscapes_labels.csv: COL-COR-SNE-SSW, ID NUMBER\n    filename_list = natsorted(os.listdir(input_dir))\n    COL_list = []\n    COR_list = []\n    SNE_list = []\n    SSW_list = []\n    for filename in filename_list:\n        if 'COL' in filename:\n            COL_list.append(filename)\n        if 'COR' in filename:\n            COR_list.append(filename)\n        if 'SNE' in filename:\n            SNE_list.append(filename)\n        if 'SSW' in filename:\n            SSW_list.append(filename)\n\n    ordered_list = COL_list + COR_list + SNE_list + SSW_list\n    # print(ordered_list)\n\n    for filename in ordered_list:\n        audio_file_path = os.path.join(input_dir, filename)\n        TEST_SPECS += get_TEST_landscape_spectrograms(audio_file_path, output_dir)\n\n    print('SUCCESSFULLY EXTRACTED {} SPECTROGRAMS'.format(len(TEST_SPECS)))  # 2400","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:11:16.644175Z","iopub.execute_input":"2022-05-16T17:11:16.644939Z","iopub.status.idle":"2022-05-16T17:12:06.171292Z","shell.execute_reply.started":"2022-05-16T17:11:16.644901Z","shell.execute_reply":"2022-05-16T17:12:06.170082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree('./TEST_SOUNDSCAPES_MEL_DATASET')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:12:06.178011Z","iopub.execute_input":"2022-05-16T17:12:06.178623Z","iopub.status.idle":"2022-05-16T17:12:06.18326Z","shell.execute_reply.started":"2022-05-16T17:12:06.178579Z","shell.execute_reply":"2022-05-16T17:12:06.182367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = Image.open('./TEST_SOUNDSCAPES_MEL_DATASET/11254_COR_5.png')\nimage","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:12:06.184984Z","iopub.execute_input":"2022-05-16T17:12:06.185477Z","iopub.status.idle":"2022-05-16T17:12:06.20208Z","shell.execute_reply.started":"2022-05-16T17:12:06.185443Z","shell.execute_reply":"2022-05-16T17:12:06.201117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# META\nmeta_sound_df = pd.DataFrame(list(zip(meta_lat, meta_lon, meta_date)), columns =['latitude', 'longitude', 'date'])\nprint(meta_sound_df)\n\n# NORMALIZE \nfor idx, col in enumerate(['latitude', 'longitude', 'date']):\n    meta_sound_df[col] = ( meta_sound_df[col] - META_MEAN[idx] ) / META_STD[idx]\n\na = meta_sound_df.columns    \n# REPEAT: repeat each row in meta_sound_df 600s/5s times:\nmeta_sound_df = pd.DataFrame(np.repeat(meta_sound_df.values, 120, axis=0))\nmeta_sound_df.columns = a\nmeta_sound_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:12:06.20473Z","iopub.execute_input":"2022-05-16T17:12:06.205151Z","iopub.status.idle":"2022-05-16T17:12:06.240333Z","shell.execute_reply.started":"2022-05-16T17:12:06.205106Z","shell.execute_reply":"2022-05-16T17:12:06.239435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_sound_tensor = torch.tensor([meta_sound_df['latitude'].values, meta_sound_df['longitude'].values, meta_sound_df['date'].values]).float()\nmeta_sound_tensor = torch.transpose(meta_sound_tensor, 0, 1)\n# meta_sound_tensor, meta_sound_tensor.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:12:06.242059Z","iopub.execute_input":"2022-05-16T17:12:06.242597Z","iopub.status.idle":"2022-05-16T17:12:06.255585Z","shell.execute_reply.started":"2022-05-16T17:12:06.242544Z","shell.execute_reply":"2022-05-16T17:12:06.254607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_inference =  transforms.Compose([transforms.Grayscale(), \n                                           transforms.ToTensor(), \n                                           transforms.Normalize(mean=DATA_MEAN, std=DATA_STD)])\ndef image_loader(image_path):\n    \"\"\"load image, returns cuda tensor\"\"\"\n    image = Image.open(image_path)\n    image = transform_inference(image)\n    image = image.unsqueeze(0)  # adds dimension 0 of size 1 (batch dim) to obtain 1x1x48x128\n    if device.type == 'cuda':\n        return image.cuda()\n    else:\n        return image","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:12:06.257261Z","iopub.execute_input":"2022-05-16T17:12:06.257931Z","iopub.status.idle":"2022-05-16T17:12:06.267035Z","shell.execute_reply.started":"2022-05-16T17:12:06.257886Z","shell.execute_reply":"2022-05-16T17:12:06.266064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# birds frequently mispredicted as nocalls:\n# birds_as_nocalls10 = list(['bkcchi', 'bobfly1', 'chswar', 'comyel', 'eastow', 'reevir1', 'rewbla', 'rucwar', 'sonspa'])\n\n# nocalls frequently mispredicted as birds:\n# nocalls_as_birds10 = list(['bcnher', 'bkcchi', 'carchi', 'grhowl', 'rewbla', 'whtspa'])     # too many grhowls ('great horned owl')!","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:12:06.268974Z","iopub.execute_input":"2022-05-16T17:12:06.269603Z","iopub.status.idle":"2022-05-16T17:12:06.282421Z","shell.execute_reply.started":"2022-05-16T17:12:06.269558Z","shell.execute_reply":"2022-05-16T17:12:06.281389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list in a dataframe pair of birds frequently heard together\nfrom itertools import combinations\ntruth = pd.read_csv('../input/birdclef-2021/train_soundscape_labels.csv')\n\ngroups = truth[truth['birds'].str.split().str.len() > 1]\ngroups['birds'] = groups['birds'].apply(lambda x: list(combinations(x.split(' '), 2)))\npairs = groups.explode('birds', ignore_index=True)\npairs_count = pd.DataFrame(np.stack(np.unique(pairs['birds'], return_counts = True), axis = 1),\n                                   columns = ['birds', 'occurrences'])\ncommon_pairs = pairs_count[pairs_count['occurrences']>10]\ncommon_pairs['birds'] = [' '.join(map(str, l)) for l in common_pairs['birds']]\ncommon_pairs = common_pairs.sort_values(by=['occurrences'], ascending=False)\ncommon_pairs","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:12:06.285105Z","iopub.execute_input":"2022-05-16T17:12:06.285737Z","iopub.status.idle":"2022-05-16T17:12:06.330802Z","shell.execute_reply.started":"2022-05-16T17:12:06.285679Z","shell.execute_reply":"2022-05-16T17:12:06.329927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict MULTILABEL\ntest_soundscapes_dir =  './TEST_SOUNDSCAPES_MEL_DATASET'\nfrom torch.nn import AvgPool2d\nfrom collections import deque\n\nCol_averager = AvgPool2d(kernel_size =(6,128*4))                     # 20 seconds\nPatch_averager = AvgPool2d(kernel_size =(6,4))\nlast_saved = 0         # saved last_birds number (between these, accept lower probabilities for species1)\nX = 10                  # number of highest score guesses to check for birds related to species1 (multilabel)\nmultilabel = False\n\n# Store the results\ndata = {'row_id': [], 'prediction': [], 'score': []}\nwith torch.no_grad():\n    cnt = 0\n    last_birds = deque(maxlen=last_saved)\n    for idx, spec_name in enumerate(os.listdir(test_soundscapes_dir)):\n        if idx % 120 == 0:                               # new 10 minutes audio (120*5s)\n            last_birds = deque(maxlen=last_saved)\n            print('audio n. ', int(idx/120))\n        path = os.path.join(test_soundscapes_dir, spec_name)\n        \n        spec = image_loader(path)\n        meta = meta_sound_tensor[idx].unsqueeze(0)\n        spec, meta = spec.to(device), meta.to(device)\n        model.eval()\n        \n        # repeat 2/4/6 times to reach 10/20/30 seconds\n        spec = torch.cat((spec, spec, spec, spec),-1)               # 20 seconds\n        prediction = nn.functional.softmax(model([spec, meta]))[0]\n        prediction = torch.Tensor.cpu(prediction)\n        \n        # store 1st, 2nd and first X guesses (the latter to be used in case of birds frequently heard together)\n        idx2,idx1 = np.argpartition(prediction, -2)[-2:]            # indices of the 2 highest scores (max on the right)\n        bestX_idx = np.argpartition(prediction, -X)[-X:]            # indices of the X highest scores\n        species1, species2 = all_species[idx1], all_species[idx2]\n        score1, score2 = prediction[idx1], prediction[idx2]         # 2 highest scores\n        bestX = list(all_species[bestX_idx])                        # X highest scores\n        bestX.remove(species1)                                      # (species1 removed)\n        \n        data['row_id'].append(spec_name.rsplit('.', 1)[0])\n        \n        # filter2: separate birdcalls | nocalls\n        AvgCol = Col_averager(spec)            # 1x1x8x1\n        AvgPatches = Patch_averager(spec)      # 1x1x8x128\n        diff = AvgPatches - AvgCol             # 1x1x8x128\n        diff = diff.view(diff.shape[0], -1)    # 1x(8*128)\n        birdcall = np.any(np.absolute(np.array(torch.Tensor.cpu(diff)))>0.63, axis=1)\n        \n        bird2_flag = 0\n        if birdcall and (species1 != 'grhowl') and (score1>0.28 or (last_birds.count(species1)>=3 and score1>0.15)):# or (species1 in birds_as_nocalls10 and score1>0.3):\n            last_birds.append(species1)\n            has_rel_birds = common_pairs['birds'].str.contains(species1)                   # if 'common_pairs' rows contain species1\n            if any(has_rel_birds):\n                rel_pairs = pd.DataFrame(common_pairs.loc[has_rel_birds])                  # rows containing species1\n                bestX_pattern = '|'.join(bestX)\n                rel_pairs['in_bestX'] = rel_pairs['birds'].str.contains(bestX_pattern)     # rows True if bird2 in row is in bestX\n                rel_pairs_in10 = rel_pairs.loc[rel_pairs['in_bestX']]['birds'].to_list()   # list of pairs with bird2 in bestX\n                if rel_pairs_in10:\n                    rel_bird = rel_pairs_in10[0].rsplit(' ')            # keep first pair, split it\n                    rel_bird.remove(species1)                           # bird related to species1\n                    rel_bird = str(rel_bird)\n                    bird2_flag = 1\n                    species2 = rel_bird\n            \n            if score1 < 0.35:     # add 'nocall' label anyway\n                if multilabel and bird2_flag:                            # multi-birds label is inaccurate\n                    data['prediction'].append({species1, species2, 'nocall'})\n                    cnt +=2\n                else:\n                    data['prediction'].append({species1, 'nocall'})\n                    cnt += 1\n            else:\n                if multilabel and bird2_flag:\n                    data['prediction'].append({species1, species2})\n                    cnt +=2\n                else:\n                    data['prediction'].append({species1})\n                    cnt += 1\n        else:\n            data['prediction'].append({'nocall'})\n        # Add the confidence score\n        data['score'].append( str(score1.item()) + ' ' + str(score2.item()) )\n\nprint('SOUNDSCAPE ANALYSIS DONE. FOUND {} BIRDS.'.format(cnt))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:12:06.332596Z","iopub.execute_input":"2022-05-16T17:12:06.332914Z","iopub.status.idle":"2022-05-16T17:14:02.240078Z","shell.execute_reply.started":"2022-05-16T17:12:06.332873Z","shell.execute_reply":"2022-05-16T17:14:02.238049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame(data, columns = ['row_id', 'prediction', 'score'])       # new dataframe\nresults = pd.merge(truth, results, on='row_id')                                 # merge with true labels\n\n# Let's look at some entries\nresults[1900:1950]","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:14:02.24388Z","iopub.execute_input":"2022-05-16T17:14:02.244481Z","iopub.status.idle":"2022-05-16T17:14:02.293561Z","shell.execute_reply.started":"2022-05-16T17:14:02.244427Z","shell.execute_reply":"2022-05-16T17:14:02.292638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_species_nocall = np.append('nocall', all_species)\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer(classes = all_species_nocall)\n\ny_prediction = list(results['prediction'])\ny_pred_matrix = mlb.fit_transform(y_prediction)\n\n# true birds list to list of sets\ny_truth = []\nfor element in list(results['birds']):\n    y_truth.append(set(element.split()))\ny_true_matrix = mlb.fit_transform(y_truth)\n\nf1 = f1_score(y_true_matrix, y_pred_matrix, average='micro')\nprint('F1 = %.3f' %(f1))\n\nf1_398 = f1_score(y_true_matrix, y_pred_matrix, average=None)            # f1 for each class\nprint('\\n', 'F1_classes:\\n', f1_398)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:14:02.295403Z","iopub.execute_input":"2022-05-16T17:14:02.296032Z","iopub.status.idle":"2022-05-16T17:14:02.539986Z","shell.execute_reply.started":"2022-05-16T17:14:02.295987Z","shell.execute_reply":"2022-05-16T17:14:02.539091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict ONELABEL\ntest_soundscapes_dir =  './TEST_SOUNDSCAPES_MEL_DATASET'\nfrom torch.nn import AvgPool2d\n\nCol_averager = AvgPool2d(kernel_size =(6,128*4))                     # 20 seconds\nPatch_averager1 = AvgPool2d(kernel_size =(6,4))\nPatch_averager2 = AvgPool2d(kernel_size =(8,7))\n\n# Store the results\ndata = {'row_id': [], 'prediction': [], 'score': []}\ndata_no_grhowl = {'row_id': [], 'prediction': [], 'score': []}\ndata_no_grhowl_thresh = {'row_id': [], 'prediction': [], 'score': []}\n\nwith torch.no_grad():\n    cnt1,cnt2,cnt3 = 0, 0, 0\n    for idx, spec_name in enumerate(os.listdir(test_soundscapes_dir)):\n        path = os.path.join(test_soundscapes_dir, spec_name)\n        \n        spec = image_loader(path)\n        meta = meta_sound_tensor[idx].unsqueeze(0)\n        spec, meta = spec.to(device), meta.to(device)\n        model.eval()\n        \n        # ripeto per 2/4/6 così raggiungo 10/20/30 secondi\n        spec = torch.cat((spec, spec, spec, spec),-1)                            # 20 seconds\n        prediction = nn.functional.softmax(model([spec, meta]))[0]\n        prediction = torch.Tensor.cpu(prediction)\n        idx = np.argmax(prediction)     # highest score index\n        species = all_species[idx]\n        score = prediction[idx]         # highest score\n\n        data['row_id'].append(spec_name.rsplit('.', 1)[0])\n        data_no_grhowl['row_id'].append(spec_name.rsplit('.', 1)[0])\n        data_no_grhowl_thresh['row_id'].append(spec_name.rsplit('.', 1)[0])\n        \n        AvgCol = Col_averager(spec)\n        AvgPatches = Patch_averager1(spec)\n        diff = AvgPatches - AvgCol\n        diff = diff.view(diff.shape[0], -1)\n        val = int(np.any(np.absolute(np.array(torch.Tensor.cpu(diff)))>0.63, axis=1))\n\n        #1\n        if val:\n            data['prediction'].append(species)\n            cnt1 += 1\n        else:\n            data['prediction'].append('nocall')\n        \n        #2\n        if val and species != 'grhowl':\n            data_no_grhowl['prediction'].append(species)\n            cnt2 += 1\n        else:\n            data_no_grhowl['prediction'].append('nocall')   \n        \n        #3\n        if val and species != 'grhowl' and score>0.30:\n            data_no_grhowl_thresh['prediction'].append(species)\n            cnt3 += 1\n        else:\n            data_no_grhowl_thresh['prediction'].append('nocall')   \n        \n        # Add the confidence score\n        data['score'].append(score.item())\n        data_no_grhowl['score'].append(score.item())\n        data_no_grhowl_thresh['score'].append(score.item())\n\nprint('SOUNDSCAPE ANALYSIS DONE. FOUND {0}, {1}, {2} BIRDS.'.format(cnt1, cnt2, cnt3))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:14:02.541757Z","iopub.execute_input":"2022-05-16T17:14:02.542382Z","iopub.status.idle":"2022-05-16T17:15:57.510738Z","shell.execute_reply.started":"2022-05-16T17:14:02.542332Z","shell.execute_reply":"2022-05-16T17:15:57.509813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data\nresults = pd.DataFrame(data, columns = ['row_id', 'prediction', 'score'])       # new dataframe\nresults = pd.merge(truth, results, on='row_id')                                 # merge with true labels\n\nonly_birds = results.loc[results['birds'] != 'nocall']           # dataframe: only rows with truth != 'nocall'\nn_birds = only_birds.shape[0]                                    # rows with truth != 'nocall': shape= (871, 7)\nn_nocalls = results.loc[results['birds'] == 'nocall'].shape[0]   # rows with truth == 'nocall': shape= (1529, 7) (63%)\n\ncorrect_birds = sum([x[0] in x[1] for x in zip(only_birds['prediction'], only_birds['birds'])])                  # birds correctly predicted\ncorrect_nocalls = results.loc[results['birds'] == 'nocall'][results['birds'] == results['prediction']].shape[0]  # nocall correctly predicted\nbirds_as_birds = only_birds[results['prediction'] != 'nocall'].shape[0]                                          # birds predicted as birds:\n\nprint('Correct birds:', correct_birds, '(%.3f %%)' %((correct_birds/n_birds)*100))\nprint('Birds predicted as birds:', birds_as_birds, '(%.3f %%)' %((birds_as_birds/n_birds)*100))\nprint('Correct nocalls:', correct_nocalls, '(%.3f %%)' %((correct_nocalls/n_nocalls)*100))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:15:57.512118Z","iopub.execute_input":"2022-05-16T17:15:57.512417Z","iopub.status.idle":"2022-05-16T17:15:57.542758Z","shell.execute_reply.started":"2022-05-16T17:15:57.512383Z","shell.execute_reply":"2022-05-16T17:15:57.541868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data, no 'grhowl' label  -> % of birds predicted as birds are grhowl, but they were misclassified\nresults = pd.DataFrame(data_no_grhowl, columns = ['row_id', 'prediction', 'score'])    # new dataframe\nresults = pd.merge(truth, results, on='row_id')                                        # merge with true labels\n\nonly_birds = results.loc[results['birds'] != 'nocall']           # dataframe: only rows with truth != 'nocall'\n\ncorrect_birds = sum([x[0] in x[1] for x in zip(only_birds['prediction'], only_birds['birds'])])                  # birds correctly predicted\ncorrect_nocalls = results.loc[results['birds'] == 'nocall'][results['birds'] == results['prediction']].shape[0]  # nocall correctly predicted\nbirds_as_birds = only_birds[results['prediction'] != 'nocall'].shape[0]                                          # birds predicted as birds:\n\nprint('Correct birds:', correct_birds, '(%.3f %%)' %((correct_birds/n_birds)*100))\nprint('Birds predicted as birds:', birds_as_birds, '(%.3f %%)' %((birds_as_birds/n_birds)*100))\nprint('Correct nocalls:', correct_nocalls, '(%.3f %%)' %((correct_nocalls/n_nocalls)*100))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:15:57.544184Z","iopub.execute_input":"2022-05-16T17:15:57.545085Z","iopub.status.idle":"2022-05-16T17:15:57.573606Z","shell.execute_reply.started":"2022-05-16T17:15:57.54504Z","shell.execute_reply":"2022-05-16T17:15:57.572507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data, no 'grhowl' label, score threshold  -> % of birds predicted as birds have score<0.3, but they provided only 1% of correct birds\nresults = pd.DataFrame(data_no_grhowl_thresh, columns = ['row_id', 'prediction', 'score'])   # dataframe\nresults = pd.merge(truth, results, on='row_id')                                              # merge with true labels\n\nonly_birds = results.loc[results['birds'] != 'nocall']           # dataframe: only rows with truth != 'nocall'\n\ncorrect_birds = sum([x[0] in x[1] for x in zip(only_birds['prediction'], only_birds['birds'])])                  # birds correctly predicted\ncorrect_nocalls = results.loc[results['birds'] == 'nocall'][results['birds'] == results['prediction']].shape[0]  # nocall correctly predicted\nbirds_as_birds = only_birds[results['prediction'] != 'nocall'].shape[0]                                          # birds predicted as birds:\n\nprint('Correct birds:', correct_birds, '(%.3f %%)' %((correct_birds/n_birds)*100))\nprint('Birds predicted as birds:', birds_as_birds, '(%.3f %%)' %((birds_as_birds/n_birds)*100))\nprint('Correct nocalls:', correct_nocalls, '(%.3f %%)' %((correct_nocalls/n_nocalls)*100))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:15:57.575124Z","iopub.execute_input":"2022-05-16T17:15:57.575688Z","iopub.status.idle":"2022-05-16T17:15:57.604018Z","shell.execute_reply.started":"2022-05-16T17:15:57.575644Z","shell.execute_reply":"2022-05-16T17:15:57.603197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# birds predicted as nocalls\nbirds_as_nocalls = only_birds[results['prediction'] == 'nocall']\n# divide group of birds to get total number of occurrence per bird\nbirds_as_nocalls_SPLIT = birds_as_nocalls.assign(birds=birds_as_nocalls['birds'].str.split(' ')).explode('birds')\n# create dataframe with number of occurrences\nbirds_as_nocalls_df = pd.DataFrame(np.stack(np.unique(birds_as_nocalls_SPLIT['birds'], return_counts = True), axis = 1),\n                                   columns = ['birds', 'number'])\nmost_freq_mispredicted_birds = birds_as_nocalls_df.loc[birds_as_nocalls_df['number'] > 10].sort_values('number', ascending = False)\nmost_freq_mispredicted_birds","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:15:57.605832Z","iopub.execute_input":"2022-05-16T17:15:57.606522Z","iopub.status.idle":"2022-05-16T17:15:57.634637Z","shell.execute_reply.started":"2022-05-16T17:15:57.606465Z","shell.execute_reply":"2022-05-16T17:15:57.633621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# nocalls predicted as birds\n# nocalls_as_birds = only_nocalls[results['prediction'] != 'nocall']\n# # create dataframe with number of occurrences\n# nocalls_as_birds_df = pd.DataFrame(np.stack(np.unique(nocalls_as_birds['prediction'], return_counts = True), axis = 1),\n#                                    columns = ['birds', 'number'])\n# most_freq_mispredicted_nocalls = nocalls_as_birds_df.loc[nocalls_as_birds_df['number'] > 10]\n# most_freq_mispredicted_nocalls","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:15:57.636263Z","iopub.execute_input":"2022-05-16T17:15:57.636768Z","iopub.status.idle":"2022-05-16T17:15:57.640404Z","shell.execute_reply.started":"2022-05-16T17:15:57.636733Z","shell.execute_reply":"2022-05-16T17:15:57.639781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# onelabel accuracy (no additional 'nocall' label if score<0.35)\n# with last results = pd.DataFrame(data_no_grhowl_thresh, ...) :\nf1 = f1_score(results['prediction'], results['birds'], average = 'micro')\naccuracy = sum([x[0] in x[1] for x in zip(results['prediction'], results['birds'])])/2400\nprint('Accuracy = %.1f %%' %(accuracy*100))\nprint('F1 = %.5f' %(f1))\n\n# Test accuracy (on train_soundscapes) of a fake model classifying all as 'nocall' is 63.7%!!!","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:15:57.641695Z","iopub.execute_input":"2022-05-16T17:15:57.642373Z","iopub.status.idle":"2022-05-16T17:15:57.687274Z","shell.execute_reply.started":"2022-05-16T17:15:57.642331Z","shell.execute_reply":"2022-05-16T17:15:57.686395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree('./TEST_SOUNDSCAPES_MEL_DATASET')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T17:15:57.689337Z","iopub.execute_input":"2022-05-16T17:15:57.689598Z","iopub.status.idle":"2022-05-16T17:15:57.69942Z","shell.execute_reply.started":"2022-05-16T17:15:57.689569Z","shell.execute_reply":"2022-05-16T17:15:57.698393Z"},"trusted":true},"execution_count":null,"outputs":[]}]}