{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm.notebook import tqdm, trange\nimport os\nfrom typing import Mapping, Union, Optional, Callable, Dict\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import Dataset, Subset, DataLoader, SubsetRandomSampler, TensorDataset, ConcatDataset\nimport warnings\nwarnings.filterwarnings(action='ignore')","metadata":{"execution":{"iopub.status.busy":"2022-05-12T10:43:48.208573Z","iopub.execute_input":"2022-05-12T10:43:48.208854Z","iopub.status.idle":"2022-05-12T10:43:48.219469Z","shell.execute_reply.started":"2022-05-12T10:43:48.208814Z","shell.execute_reply":"2022-05-12T10:43:48.218207Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Dataset and data distribution","metadata":{}},{"cell_type":"code","source":"SAMPLING_RATE = 32000 # Hertz\nINPUT_LENGTH = 5      # seconds\nSPEC_SHAPE = (48,128) # spectrogram shape\nFMIN=500              # Hz (~min frequency for birds)\nFMAX=12500            # Hz (~max frequency for birds)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T10:43:52.811010Z","iopub.execute_input":"2022-05-12T10:43:52.811364Z","iopub.status.idle":"2022-05-12T10:43:52.817797Z","shell.execute_reply.started":"2022-05-12T10:43:52.811328Z","shell.execute_reply":"2022-05-12T10:43:52.816707Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_dataset_path = \"./dataset\"\nzip_path = \"../input/bird-dataset-20s/melspec_dataset_20s.zip\"\nDATA_MEAN = 0.3674\nDATA_STD = 0.1928\nimport zipfile\nwith zipfile.ZipFile(zip_path, 'r') as zip_ref:\n    zip_ref.extractall(train_dataset_path)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T10:43:56.834104Z","iopub.execute_input":"2022-05-12T10:43:56.834643Z","iopub.status.idle":"2022-05-12T10:44:46.046105Z","shell.execute_reply.started":"2022-05-12T10:43:56.834596Z","shell.execute_reply":"2022-05-12T10:44:46.045202Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class AddGaussianNoise(object):\n    def __init__(self, mean=0., std=1.):\n        self.std = std\n        self.mean = mean\n        \n    def __call__(self, tensor):\n        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n    \n    def __repr__(self):\n        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n\nclass TimeRecombination(object):\n    def __init__(self, partition):\n        self.partition = partition\n    \n    def __call__(self, tensor):\n        if tensor.shape[-1] == 256:              # 10 seconds\n            if self.partition == 0:\n                pieces_width = [100,50,50,56]\n            if self.partition == 1:\n                pieces_width = [50,40,40,30,30,30,36]\n        if tensor.shape[-1] == 512:              # 20 seconds\n            if self.partition == 0:\n                pieces_width = [100,100,100,50,50,56,56]\n            if self.partition == 1:\n                pieces_width = [35,35,30,40,40,40,40,30,30,30,30,30,30,36,36]\n        if tensor.shape[-1] == 768:              # 30 seconds\n            if self.partition == 0:\n                pieces_width = [100,100,100,50,50,50,50,50,50,56,56,56]\n            if self.partition == 1:\n                pieces_width = [50,50,50,40,40,40,40,40,40,30,30,30,30,30,30,30,30,30,36,36,36]\n        random.shuffle(pieces_width)\n        tensor = torch.split(tensor, pieces_width, dim = -1)\n        return torch.cat(random.sample(tensor,len(pieces_width)), dim= -1)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T10:44:46.048054Z","iopub.execute_input":"2022-05-12T10:44:46.048745Z","iopub.status.idle":"2022-05-12T10:44:46.063785Z","shell.execute_reply.started":"2022-05-12T10:44:46.048703Z","shell.execute_reply":"2022-05-12T10:44:46.062397Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import torchaudio.transforms as audiotransf\n\ntransform =  transforms.Compose([transforms.Grayscale(), \n                                 transforms.ToTensor(), \n                                 transforms.Normalize(mean=DATA_MEAN, std=DATA_STD),\n                                 AddGaussianNoise(0., 0.2),\n                                 audiotransf.TimeMasking(time_mask_param = 150, iid_masks = True),   # MODIFY with size\n                                 audiotransf.FrequencyMasking(freq_mask_param = 5, iid_masks = True),\n                                 TimeRecombination(partition = 1)\n                                ])\ndataset = datasets.ImageFolder(root= train_dataset_path, transform=transform)\nlen(dataset), len(dataset.classes)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-12T10:44:46.065506Z","iopub.execute_input":"2022-05-12T10:44:46.065950Z","iopub.status.idle":"2022-05-12T10:44:47.147238Z","shell.execute_reply.started":"2022-05-12T10:44:46.065908Z","shell.execute_reply":"2022-05-12T10:44:47.146349Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"idx_to_class = {v:k for k,v in dataset.class_to_idx.items()}\n# dataset.class_to_idx             # lists all classes","metadata":{"execution":{"iopub.status.busy":"2022-05-12T10:44:47.149957Z","iopub.execute_input":"2022-05-12T10:44:47.150994Z","iopub.status.idle":"2022-05-12T10:44:47.155278Z","shell.execute_reply.started":"2022-05-12T10:44:47.150944Z","shell.execute_reply":"2022-05-12T10:44:47.154395Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Dataset example\nimport plotly.express as px\n\ntraining_index = random.randint(0, len(dataset))\nimage, label = dataset[training_index]    # image.shape = torch.Size([1, 48, 128])\n\nexample = np.array(image[0])              # 48x128\n\nfig = px.imshow(example, \n                title=idx_to_class[int(label)],\n                color_continuous_scale='gray', \n                color_continuous_midpoint=0,\n                labels = dict(x = 'Time (s)',y = 'Frequency (Hz)'),\n               )\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T10:44:47.156613Z","iopub.execute_input":"2022-05-12T10:44:47.157408Z","iopub.status.idle":"2022-05-12T10:44:50.574179Z","shell.execute_reply.started":"2022-05-12T10:44:47.157361Z","shell.execute_reply":"2022-05-12T10:44:50.573415Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Metadata","metadata":{}},{"cell_type":"code","source":"# Load metadata file\nmetadata_df = pd.read_csv('../input/birdclef-2021/train_metadata.csv')\nall_species = metadata_df['primary_label'].unique()\nmeta_df = metadata_df[[\"filename\",\"primary_label\",\"latitude\",\"longitude\",\"date\",\"time\",\"rating\"]]  # retain\n# TIME OF DAY NOT PRESENT ON TEST DATA: USELESS\nmeta_df","metadata":{"execution":{"iopub.status.busy":"2022-05-12T10:44:50.575864Z","iopub.execute_input":"2022-05-12T10:44:50.576219Z","iopub.status.idle":"2022-05-12T10:44:51.119687Z","shell.execute_reply.started":"2022-05-12T10:44:50.576169Z","shell.execute_reply":"2022-05-12T10:44:51.118727Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"pd.options.mode.chained_assignment = None  # default='warn'\n\n# express DATE in days (remove year)\ndef date_transform(date):\n    return int(date.rsplit('-')[2]) + max(0, int(date.rsplit('-')[1])-1)*30\nmeta_df['date'] = meta_df['date'].apply(date_transform)\n\n# express TIME in minutes\ndef time_transform(time):\n   # exclude '?', 'xx', 'xx:xx', 'night', 'am'\n    if not(any(map(str.isdigit, time))):     # if no numbers inside\n        return np.random.randint(0,1440)     # method1: in this way we will not increase a specific time slot\n    else:\n        Q = 0\n        time = time.lower()                  # AM,PM->am,pm\n        if 'pm' in time:\n            Q = 1\n        time = time.replace('pm','')\n        time = time.replace('am','')\n        time = time.rsplit(':')\n        minutes = 0\n        if len(time)>1:\n            minutes = int(time[1])\n        result = (int(time[0]) + Q*12)*60 + minutes\n        return( result%1440 )                # there are also '12:30pm', '12:15pm', '24:15', etc\nmeta_df['time'] = meta_df['time'].apply(time_transform)\nmeta_df","metadata":{"execution":{"iopub.status.busy":"2022-05-12T10:44:51.121104Z","iopub.execute_input":"2022-05-12T10:44:51.121428Z","iopub.status.idle":"2022-05-12T10:44:51.455199Z","shell.execute_reply.started":"2022-05-12T10:44:51.121384Z","shell.execute_reply":"2022-05-12T10:44:51.454399Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"f = plt.hist(meta_df['time'], 100)\nplt.show\n# suspicious peak at t=0; remove?","metadata":{"execution":{"iopub.status.busy":"2022-05-12T10:44:51.456722Z","iopub.execute_input":"2022-05-12T10:44:51.457191Z","iopub.status.idle":"2022-05-12T10:44:51.892119Z","shell.execute_reply.started":"2022-05-12T10:44:51.457147Z","shell.execute_reply":"2022-05-12T10:44:51.891244Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# NORMALIZE METADATA\nMETA_MEAN = []\nMETA_STD = []\nfor col in ['latitude', 'longitude', 'date', 'time']:\n    mean_col = meta_df[col].mean()\n    std_col = meta_df[col].std()\n    META_MEAN.append(mean_col)\n    META_STD.append(std_col)\n    meta_df[col] = ( meta_df[col] - mean_col) / std_col\nmeta_df","metadata":{"execution":{"iopub.status.busy":"2022-05-12T10:44:51.893751Z","iopub.execute_input":"2022-05-12T10:44:51.894259Z","iopub.status.idle":"2022-05-12T10:44:51.925491Z","shell.execute_reply.started":"2022-05-12T10:44:51.894212Z","shell.execute_reply":"2022-05-12T10:44:51.924802Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"META_STD","metadata":{"execution":{"iopub.status.busy":"2022-05-12T10:45:33.218751Z","iopub.execute_input":"2022-05-12T10:45:33.219074Z","iopub.status.idle":"2022-05-12T10:45:33.225213Z","shell.execute_reply.started":"2022-05-12T10:45:33.219041Z","shell.execute_reply":"2022-05-12T10:45:33.224507Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# repeat each row in meta_df 'duration' times:\nduration_df = pd.read_csv('../input/bird-dataset-20s/duration.csv', header=None)  # inport duration (n*5 seconds)\nduration_df = duration_df[0]\n\n# DEPENDS ON DATASET!\n\n# 0) first5s\n# # meta_df is left unchanged\n\n# 1) whole dataset\n# meta_df = meta_df.loc[meta_df.index.repeat(duration_df)]\n\n# 2) dataset: rating >=4\n# duration_df = duration_df.loc[meta_df.query('rating>=4').index]\n# meta_df = meta_df.query('rating>=4')\n# meta_df = meta_df.loc[meta_df.index.repeat(duration_df)]\n\n# 3) first_last5s\n# meta_df = meta_df.loc[meta_df.index.repeat(2)]\n\n# 4) 10 seconds\n# meta_df = meta_df.loc[duration_df.loc[duration_df>=2].index]   # 5*2=10\n# duration_df = duration_df.loc[duration_df>=2]     # shape= \n# meta_df = meta_df.loc[meta_df.index.repeat(duration_df/2)]\n\n# 5) 20 seconds\nmeta_df = meta_df.loc[duration_df.loc[duration_df>=4].index]     # 5*4=20\nduration_df = duration_df.loc[duration_df>=4]                    # shape= 45278\nmeta_df = meta_df.loc[meta_df.index.repeat(duration_df/4)]\n\n# 6) 30 seconds\n# meta_df = meta_df.loc[duration_df.loc[duration_df>=6].index]   # 5*6=30\n# duration_df = duration_df.loc[duration_df>=6]                  # shape= 45278\n# meta_df = meta_df.loc[meta_df.index.repeat(duration_df/6)]","metadata":{"execution":{"iopub.status.busy":"2022-05-11T13:04:52.723695Z","iopub.execute_input":"2022-05-11T13:04:52.724359Z","iopub.status.idle":"2022-05-11T13:04:53.011682Z","shell.execute_reply.started":"2022-05-11T13:04:52.724321Z","shell.execute_reply":"2022-05-11T13:04:53.010914Z"},"trusted":true},"execution_count":328,"outputs":[]},{"cell_type":"code","source":"# get meta_tensor\nmeta_tensor = torch.tensor([meta_df['latitude'].values, meta_df['longitude'].values, meta_df['date'].values]).float()\nmeta_tensor = torch.transpose(meta_tensor, 0, 1)\nmeta_tensor.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-11T13:04:53.012828Z","iopub.execute_input":"2022-05-11T13:04:53.013369Z","iopub.status.idle":"2022-05-11T13:04:53.328826Z","shell.execute_reply.started":"2022-05-11T13:04:53.013324Z","shell.execute_reply":"2022-05-11T13:04:53.327872Z"},"trusted":true},"execution_count":329,"outputs":[]},{"cell_type":"code","source":"# create meta_dataset\nmeta_dataset = TensorDataset(meta_tensor)   # dataset without targets\nlen(meta_dataset) == len(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T13:04:53.330006Z","iopub.execute_input":"2022-05-11T13:04:53.330232Z","iopub.status.idle":"2022-05-11T13:04:53.336379Z","shell.execute_reply.started":"2022-05-11T13:04:53.330204Z","shell.execute_reply":"2022-05-11T13:04:53.335671Z"},"trusted":true},"execution_count":330,"outputs":[]},{"cell_type":"markdown","source":"## Filtered data, train and validation sets","metadata":{}},{"cell_type":"code","source":"# loader = DataLoader(dataset, batch_size=1024, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:27:42.462635Z","iopub.execute_input":"2022-05-11T11:27:42.463286Z","iopub.status.idle":"2022-05-11T11:27:42.474900Z","shell.execute_reply.started":"2022-05-11T11:27:42.463249Z","shell.execute_reply":"2022-05-11T11:27:42.474022Z"},"trusted":true},"execution_count":227,"outputs":[]},{"cell_type":"code","source":"'''\n# compute pixels mean on each row (avg pool on 128-pixel wide rectangles)\n# compute pixels sum on fixed size rectangles, then compare to mean (avg pool on smaller rectangles)\n\nfrom torch.nn import AvgPool2d\n\nPatch_averager = AvgPool2d(kernel_size =(8,7))         # filter1\n# Col_averager = AvgPool2d(kernel_size =(6,128*4))       # filter2\n# Patch_averager = AvgPool2d(kernel_size =(6,4))         # filter2\n\ngood_array = np.array([]).astype(int)\nspecies_good_cnt = np.zeros(len(dataset.classes))\n\ntqdm_iterator = tqdm(\n    enumerate(loader),\n    total=len(loader),\n    leave=False,\n)\nbatch_size = 1024\nfor batch_idx, (data,target) in tqdm_iterator:\n\n    # filter1\n    AvgPatches = Patch_averager(data[:,:,:,:-2])\n    diff = torch.diff(AvgPatches, dim=3)\n    diff = diff.view(diff.shape[0], -1)\n    # select indices in each batch:\n    inner_idx_good = np.where(np.any(np.absolute(np.array(diff))>0.58,axis=1))[0].astype(int)\n\n#     # filter2\n#     AvgCol = Col_averager(data)         # 64x1x12\n#     AvgPatches = Patch_averager(data)\n#     diff = AvgPatches - AvgCol          # 64x1x12x32\n#     diff = diff.view(diff.shape[0], -1) # 64x(12*32)\n#     # select indices in each batch:\n#     inner_idx_good = np.where(np.any(np.array(diff)>0.63,axis=1))[0].astype(int)\n#     inner_idx_good = inner_idx_good[np.array(species_good_cnt[np.array(target.reshape(-1)[torch.tensor(inner_idx_good)])] < 4000)] \n    \n    # count species for each group\n    a1, b1 = np.unique(target[np.array(inner_idx_good)], return_counts = True)\n    species_good_cnt[a1] += b1\n    # create list for the entire dataset\n    good_indices = batch_idx*batch_size + inner_idx_good\n    good_array = np.append(good_array, good_indices)\n\nlen(good_array)\n'''\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:57:39.882294Z","iopub.execute_input":"2022-05-11T12:57:39.882608Z","iopub.status.idle":"2022-05-11T12:57:39.889261Z","shell.execute_reply.started":"2022-05-11T12:57:39.882563Z","shell.execute_reply":"2022-05-11T12:57:39.888245Z"},"trusted":true},"execution_count":311,"outputs":[]},{"cell_type":"code","source":"# # good/all ratio\n\n# all_birds = meta_df['primary_label'].value_counts(sort=False)\n# all_birds, species_good_cnt/all_birds,","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:27:42.491762Z","iopub.execute_input":"2022-05-11T11:27:42.492432Z","iopub.status.idle":"2022-05-11T11:27:42.506014Z","shell.execute_reply.started":"2022-05-11T11:27:42.492379Z","shell.execute_reply":"2022-05-11T11:27:42.505217Z"},"trusted":true},"execution_count":229,"outputs":[]},{"cell_type":"code","source":"# thrown_away = all_birds - species_good_cnt\n# plt.plot(list(range(len(dataset.classes))), species_good_cnt)\n# plt.plot(list(range(len(dataset.classes))), thrown_away)\n# plt.legend(['selected birds (tot {})' .format(species_good_cnt.sum()), \n#             'thrown away (tot {})' .format(thrown_away.sum())])\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:27:42.507360Z","iopub.execute_input":"2022-05-11T11:27:42.507866Z","iopub.status.idle":"2022-05-11T11:27:42.518745Z","shell.execute_reply.started":"2022-05-11T11:27:42.507815Z","shell.execute_reply":"2022-05-11T11:27:42.518018Z"},"trusted":true},"execution_count":230,"outputs":[]},{"cell_type":"code","source":"# thrown_away = all_birds - species_good_cnt\n# plt.plot(list(range(len(dataset.classes))), species_good_cnt/all_birds)\n# plt.plot(list(range(len(dataset.classes))), thrown_away/all_birds)\n# plt.legend(['% selected birds', '% thrown away'])\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:27:42.520109Z","iopub.execute_input":"2022-05-11T11:27:42.520497Z","iopub.status.idle":"2022-05-11T11:27:42.534997Z","shell.execute_reply.started":"2022-05-11T11:27:42.520459Z","shell.execute_reply":"2022-05-11T11:27:42.534314Z"},"trusted":true},"execution_count":231,"outputs":[]},{"cell_type":"code","source":"# good_list = good_array.tolist()\n\n# import csv\n# with open('good_list4.1_1.8.csv', 'w') as f:\n#     writer = csv.writer(f)\n#     writer.writerow(list(range(len(good_list))))\n#     writer.writerow(good_list)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:27:42.536076Z","iopub.execute_input":"2022-05-11T11:27:42.536400Z","iopub.status.idle":"2022-05-11T11:27:42.548295Z","shell.execute_reply.started":"2022-05-11T11:27:42.536371Z","shell.execute_reply":"2022-05-11T11:27:42.547350Z"},"trusted":true},"execution_count":232,"outputs":[]},{"cell_type":"code","source":"# # good_list from file:\n# good_df = pd.read_csv('../input/good-list/good_list4.1_1.5.csv')\n# good_list = good_df.values.tolist()[0]\n\n# len(good_list)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:27:42.549731Z","iopub.execute_input":"2022-05-11T11:27:42.550025Z","iopub.status.idle":"2022-05-11T11:27:42.559731Z","shell.execute_reply.started":"2022-05-11T11:27:42.549992Z","shell.execute_reply":"2022-05-11T11:27:42.558808Z"},"trusted":true},"execution_count":233,"outputs":[]},{"cell_type":"code","source":"filtered = 0              # all data\n# filtered = 1              # filtered data\n# filtered = 2              # random data, len = len(good_list)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T13:04:53.337677Z","iopub.execute_input":"2022-05-11T13:04:53.337929Z","iopub.status.idle":"2022-05-11T13:04:53.349564Z","shell.execute_reply.started":"2022-05-11T13:04:53.337900Z","shell.execute_reply":"2022-05-11T13:04:53.348838Z"},"trusted":true},"execution_count":331,"outputs":[]},{"cell_type":"code","source":"np.random.seed(0)\ntorch.manual_seed(0)\n\nval_split_ratio = 0.2\n\nif filtered == 0:\n    VAL_TOT = int(np.floor(len(dataset)*val_split_ratio))\n    dataset_indices = list(range(len(dataset)))\n    np.random.shuffle(dataset_indices)\n    split_index = int(np.floor(val_split_ratio*len(dataset)))\nelif filtered == 1:\n    VAL_TOT = int(np.floor(len(good_list)*val_split_ratio))\n    dataset_indices = good_list\n    np.random.shuffle(dataset_indices)\n    split_index = int(np.floor(val_split_ratio*len(good_list)))\nelif filtered == 2:           # RANDOM SAMPLES, same lenght as good_list\n    VAL_TOT = int(np.floor(len(good_list)*val_split_ratio))\n    dataset_indices = list(np.random.randint(low=0, high = len(dataset), size = len(good_list)))\n    np.random.shuffle(dataset_indices)\n    split_index = int(np.floor(val_split_ratio*len(good_list)))\n\ntrain_idx, val_idx = dataset_indices[split_index:], dataset_indices[:split_index]","metadata":{"execution":{"iopub.status.busy":"2022-05-11T13:04:53.350977Z","iopub.execute_input":"2022-05-11T13:04:53.351241Z","iopub.status.idle":"2022-05-11T13:04:53.391832Z","shell.execute_reply.started":"2022-05-11T13:04:53.351208Z","shell.execute_reply":"2022-05-11T13:04:53.391129Z"},"trusted":true},"execution_count":332,"outputs":[]},{"cell_type":"code","source":"train_sampler = SubsetRandomSampler(train_idx)\nval_sampler = SubsetRandomSampler(val_idx)\n\ntrain_loader = DataLoader(dataset, batch_size=64, shuffle = False, sampler = train_sampler)\nmeta_train_loader = DataLoader(meta_dataset, batch_size=64, shuffle = False, sampler = train_sampler)\nval_loader = DataLoader(dataset, batch_size=64, shuffle = False, sampler = val_sampler)\nmeta_val_loader = DataLoader(meta_dataset, batch_size=64, shuffle = False, sampler = val_sampler)\n\nprint(\"Batch data shape (train_loader):  \", next(iter(train_loader))[0].shape)\nprint(\"Number of batches (train_loader):  \", len(train_loader))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T13:04:53.750428Z","iopub.execute_input":"2022-05-11T13:04:53.751407Z","iopub.status.idle":"2022-05-11T13:04:54.402154Z","shell.execute_reply.started":"2022-05-11T13:04:53.751355Z","shell.execute_reply":"2022-05-11T13:04:54.401227Z"},"trusted":true},"execution_count":333,"outputs":[]},{"cell_type":"code","source":"# # plotlib error =>\n# from plotly.offline import plot, iplot, init_notebook_mode\n# init_notebook_mode(connected=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:27:43.213716Z","iopub.execute_input":"2022-05-11T11:27:43.213975Z","iopub.status.idle":"2022-05-11T11:27:43.218017Z","shell.execute_reply.started":"2022-05-11T11:27:43.213945Z","shell.execute_reply":"2022-05-11T11:27:43.217018Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"markdown","source":"## The model","metadata":{}},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, input_size: int, input_channels: int, n_feature1: int, n_feature2: int, n_feature3: int, \n                 n_feature4: int, n_feature5: int, outputs: int) -> None:\n        super().__init__()\n        \n        self.n_feature1 = n_feature1\n        self.conv1 = nn.Conv2d(input_channels, n_feature1, kernel_size=3, padding = 'same')\n        self.conv2 = nn.Conv2d(n_feature1, n_feature2, kernel_size=3, padding = 'same')\n        self.conv3 = nn.Conv2d(n_feature2, n_feature3, kernel_size=3, padding = 'same')\n        self.conv4 = nn.Conv2d(n_feature3, n_feature4, kernel_size=3, padding = 'same')\n        self.conv5 = nn.Conv2d(n_feature4, n_feature5, kernel_size=3, padding = 'same')\n        \n        self.pool = nn.MaxPool2d(2,2)\n        \n        self.bn1 = nn.BatchNorm2d(n_feature1)\n        self.bn2 = nn.BatchNorm2d(n_feature2)\n        self.bn3 = nn.BatchNorm2d(n_feature3)\n        self.bn4 = nn.BatchNorm2d(n_feature4)\n        self.bn5 = nn.BatchNorm2d(n_feature5)\n        self.bnf1 = nn.BatchNorm1d(2048)        # modify along with fc dimensions\n\n        self.drop2d = nn.Dropout2d(p=0.2)\n        self.drop = nn.Dropout(p=0.4)\n                \n        self.meta_rep = 32\n        \n        self.fc1 = nn.Linear(n_feature5 * 1*16, 2048)          # 128(5s)->256(10s)->512(20s)->768(30s) => 4->8->16->24\n        self.fc2 = nn.Linear(2048 + self.meta_rep*3, outputs)\n\n    def forward(self, x: list) -> torch.Tensor:\n        \n        D = x[0]  # data\n        M = x[1]  # meta\n        Lat = M[:,0].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        Lon = M[:,1].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        Date = M[:,2].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        \n#         #APPLY MASK\n#         thresh = 0.5\n#         Col_averager = AvgPool2d(kernel_size =(1,128))\n#         condition = (D - Col_averager(D)) < thresh\n#         D[condition] = 0\n        \n        #print(x.shape)                                               # torch.Size([64, 1, 48, 768] 512] 256] 128])\n        D = self.drop2d(self.pool(self.bn1(F.relu(self.conv1(D))))) # [64, n_feature1, 24, 384] 256] 128] 64]\n        D = self.drop2d(self.pool(self.bn2(F.relu(self.conv2(D))))) # [64, n_feature2, 12, 192] 128] 64] 32]\n        D = self.drop2d(self.pool(self.bn3(F.relu(self.conv3(D))))) # [64, n_feature3, 6, 96] 64] 32] 16]\n        D = self.drop2d(self.pool(self.bn4(F.relu(self.conv4(D))))) # [64, n_feature4, 3, 48] 32] 16] 8]\n        D = self.drop2d(self.pool(self.bn5(F.relu(self.conv5(D))))) # [64, n_feature5, 1, 24] 16] 8] 4]\n        \n        \n        D = D.view(D.shape[0], -1)        \n        D = self.drop(self.bnf1(F.relu(self.fc1(D))))\n        \n        # ADD METADATA\n        D = torch.cat((D, Lat, Lon, Date),1)    # data & meta\n        \n        D = self.fc2(D)\n        return D\n\n# identity + nn.CrossEntropyLoss = F.log_softmax + nn.NLLLoss","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:27:43.219650Z","iopub.execute_input":"2022-05-11T11:27:43.219918Z","iopub.status.idle":"2022-05-11T11:27:43.236913Z","shell.execute_reply.started":"2022-05-11T11:27:43.219886Z","shell.execute_reply":"2022-05-11T11:27:43.236113Z"},"trusted":true},"execution_count":238,"outputs":[]},{"cell_type":"code","source":"# (ReLU BEFORE AND AFTER ADDITION) +dropout \nclass ResBlock1(nn.Module):\n    def __init__(self, in_channels, out_channels, downsample):\n        super().__init__()\n        if downsample:\n            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),\n                nn.BatchNorm2d(out_channels)\n            )\n        else:\n            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n            self.shortcut = nn.Sequential()\n\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.drop2d = nn.Dropout2d(p=0.1)\n\n    def forward(self, input):\n        shortcut = self.shortcut(input)\n        \n        input = nn.ReLU()(self.bn1(self.conv1(input)))          # pool substituted with stride\n        input = self.drop2d(input)\n        input = nn.ReLU()(self.bn2(self.conv2(input)))\n        input = input + shortcut\n        return nn.ReLU()(input)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:27:43.237962Z","iopub.execute_input":"2022-05-11T11:27:43.238572Z","iopub.status.idle":"2022-05-11T11:27:43.256405Z","shell.execute_reply.started":"2022-05-11T11:27:43.238536Z","shell.execute_reply":"2022-05-11T11:27:43.255395Z"},"trusted":true},"execution_count":239,"outputs":[]},{"cell_type":"code","source":"class ResBottleneckBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, downsample):\n        super().__init__()\n        self.downsample = downsample\n        self.conv1 = nn.Conv2d(in_channels, out_channels//4, kernel_size=1, stride=1)\n        self.conv2 = nn.Conv2d(out_channels//4, out_channels//4, kernel_size=3, stride=2 if downsample else 1, padding=1)\n        self.conv3 = nn.Conv2d(out_channels//4, out_channels, kernel_size=1, stride=1)\n        self.shortcut = nn.Sequential()\n        \n        if self.downsample or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2 if self.downsample else 1),\n                nn.BatchNorm2d(out_channels)\n            )\n\n        self.bn1 = nn.BatchNorm2d(out_channels//4)\n        self.bn2 = nn.BatchNorm2d(out_channels//4)\n        self.bn3 = nn.BatchNorm2d(out_channels)\n        \n        self.drop2d = nn.Dropout2d(p=0.2)      # batchnorm alone leads to overfitting\n\n    def forward(self, input):\n        shortcut = self.shortcut(input)\n        input = nn.ReLU()(self.bn1(self.conv1(input)))\n        input = self.drop2d(input)\n        input = nn.ReLU()(self.bn2(self.conv2(input)))\n        input = self.drop2d(input)\n        input = nn.ReLU()(self.bn3(self.conv3(input)))\n        input = input + shortcut\n        return nn.ReLU()(input)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T13:05:12.406456Z","iopub.execute_input":"2022-05-11T13:05:12.407061Z","iopub.status.idle":"2022-05-11T13:05:12.417899Z","shell.execute_reply.started":"2022-05-11T13:05:12.407022Z","shell.execute_reply":"2022-05-11T13:05:12.416745Z"},"trusted":true},"execution_count":334,"outputs":[]},{"cell_type":"code","source":"class ResNet(nn.Module):\n    def __init__(self, in_channels, resblock, repeat, useBottleneck=False, outputs=397):\n        super().__init__()\n        self.layer0 = nn.Sequential(\n            nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU()\n        )\n\n        if useBottleneck:\n            filters = [64, 256, 512, 1024, 2048]\n            self.meta_rep = 128\n        else:\n            filters = [64, 64, 128, 256, 512]\n            self.meta_rep = 32\n\n        self.layer1 = nn.Sequential()\n        self.layer1.add_module('conv2_1', resblock(filters[0], filters[1], downsample=False))\n        for i in range(1, repeat[0]):\n                self.layer1.add_module('conv2_%d'%(i+1,), resblock(filters[1], filters[1], downsample=False))\n\n        self.layer2 = nn.Sequential()\n        self.layer2.add_module('conv3_1', resblock(filters[1], filters[2], downsample=True))\n        for i in range(1, repeat[1]):\n                self.layer2.add_module('conv3_%d' % (i+1,), resblock(filters[2], filters[2], downsample=False))\n\n        self.layer3 = nn.Sequential()\n        self.layer3.add_module('conv4_1', resblock(filters[2], filters[3], downsample=True))\n        for i in range(1, repeat[2]):\n            self.layer3.add_module('conv2_%d' % (i+1,), resblock(filters[3], filters[3], downsample=False))\n\n        self.layer4 = nn.Sequential()\n        self.layer4.add_module('conv5_1', resblock(filters[3], filters[4], downsample=True))\n        for i in range(1, repeat[3]):\n            self.layer4.add_module('conv3_%d'%(i+1,), resblock(filters[4], filters[4], downsample=False))\n\n        self.gap = torch.nn.AdaptiveAvgPool2d(1)\n        self.fc = torch.nn.Linear(filters[4] + self.meta_rep*3, outputs)\n        self.drop = nn.Dropout(p=0.4)\n\n    def forward(self, input):\n        \n        D = input[0]  # data\n        M = input[1]  # meta\n        Lat = M[:,0].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        Lon = M[:,1].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        Date = M[:,2].unsqueeze(0).transpose(0,1).repeat(1,self.meta_rep)\n        \n        D = self.layer0(D)\n        D = self.layer1(D)\n        D = self.layer2(D)\n        D = self.layer3(D)\n        D = self.layer4(D)\n        D = self.gap(D)                # [64, feature_maps, h, w] -> [64, feature_maps, 1]\n        \n        D = D.view(D.shape[0], -1)     # [64, feature_maps, 1, 1]    ->  [64, feature_maps]\n        D = self.drop(D)\n        \n        DM = torch.cat((D, Lat, Lon, Date),1)    # data & meta\n        \n        DM = self.fc(DM)\n\n        return DM","metadata":{"execution":{"iopub.status.busy":"2022-05-11T13:05:16.306280Z","iopub.execute_input":"2022-05-11T13:05:16.306860Z","iopub.status.idle":"2022-05-11T13:05:16.325725Z","shell.execute_reply.started":"2022-05-11T13:05:16.306787Z","shell.execute_reply":"2022-05-11T13:05:16.324716Z"},"trusted":true},"execution_count":335,"outputs":[]},{"cell_type":"code","source":"x, _ = next(iter(train_loader))\ninput_size_w, input_size_h = x.shape[2], x.shape[3]\ninput_size = input_size_w * input_size_h\n\n# Define the device to use\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f'Using device: {device}') ","metadata":{"execution":{"iopub.status.busy":"2022-05-11T13:05:21.245972Z","iopub.execute_input":"2022-05-11T13:05:21.246534Z","iopub.status.idle":"2022-05-11T13:05:21.539304Z","shell.execute_reply.started":"2022-05-11T13:05:21.246481Z","shell.execute_reply":"2022-05-11T13:05:21.538384Z"},"trusted":true},"execution_count":336,"outputs":[]},{"cell_type":"code","source":"# CNN\nconvnet5 = CNN(input_size, input_channels=1, n_feature1=32, n_feature2=64, n_feature3=128, n_feature4=256, n_feature5=512, outputs=397)\nconvnet5.to(device)\n\n# resnet18\nresnet18 = ResNet(1, ResBlock1, [2, 2, 2, 2], useBottleneck=False, outputs=397)\nresnet18.to(device)\n\n# resnet34\nresnet34 = ResNet(1, ResBlock1, [3, 4, 6, 3], useBottleneck=False, outputs=397)\nresnet34.to(device)\n\n# resnet50\nresnet50 = ResNet(1, ResBottleneckBlock, [3, 4, 6, 3], useBottleneck=True, outputs=397)\nresnet50.to(device)\n\n# resnet101\nresnet101 = ResNet(1, ResBottleneckBlock, [3, 4, 23, 3], useBottleneck=True, outputs=397)\nresnet101.to(device)\n\n# resnet152\nresnet152 = ResNet(1, ResBottleneckBlock, [3, 8, 36, 3], useBottleneck=True, outputs=397)\nresnet152.to(device)\n\nprint()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-11T13:05:26.022989Z","iopub.execute_input":"2022-05-11T13:05:26.023273Z","iopub.status.idle":"2022-05-11T13:05:27.870727Z","shell.execute_reply.started":"2022-05-11T13:05:26.023244Z","shell.execute_reply":"2022-05-11T13:05:27.869737Z"},"trusted":true},"execution_count":337,"outputs":[]},{"cell_type":"code","source":"def make_averager() -> Callable[[Optional[float]], float]:\n    \"\"\" Returns a function that maintains a running average\n\n    :returns: running average function\n    \"\"\"\n    count = 0\n    total = 0\n\n    def averager(new_value: Optional[float]) -> float:\n        \"\"\" Running averager\n\n        :param new_value: number to add to the running average,\n                          if None returns the current average\n        :returns: the current average\n        \"\"\"\n        nonlocal count, total\n        if new_value is None:\n            return total / count if count else float(\"nan\")      # if count>0 => return total/count; if count=0 => return float('nan')\n        count += 1\n        total += new_value\n        return total / count\n\n    return averager\n\ndef test_model(\n    loss_func,\n    test_dl: torch.utils.data.DataLoader,\n    meta_test_dl: torch.utils.data.DataLoader,\n    model: torch.nn.Module,\n    device: str = \"cuda\"\n) -> Dict[str, Union[float, Callable[[Optional[float]], float]]]:\n    \n    model.eval()\n    test_loss_averager = make_averager()  # mantain a running average of the loss\n    correct = 0\n    with torch.no_grad():\n        for (data, target),meta in zip(test_dl, meta_test_dl):\n            # send to device\n            meta = meta[0]\n            data, target, meta = data.to(device), target.to(device), meta.to(device)\n            output = model([data, meta])\n    \n            test_loss_averager(loss_func(output, target).item())   # takes the average of the losses (cross_entropy) computed on all samples of the test set\n\n            # get the index of the max probability\n            pred = output.max(1, keepdim=True)[1]               # dim to reduce=1 (max along each row); keep dimension; [1] => indices of the maxima, [0] => maxima\n            correct += pred.eq(target.view_as(pred)).cpu().sum().item()  # \"a.eq(b)\" True if a=b; self.view_as(other) = self.view(other.size())\n\n    return {\n        \"accuracy\": 100.0 * correct / VAL_TOT,\n        \"loss_averager\": test_loss_averager,\n        \"correct\": correct,\n    }\n\ndef fit(\n    loss_func,\n    epochs: int,\n    train_dl: torch.utils.data.DataLoader,\n    meta_train_dl: torch.utils.data.DataLoader,\n    test_dl: torch.utils.data.DataLoader,\n    meta_test_dl: torch.utils.data.DataLoader,\n    model: torch.nn.Module,\n    opt: torch.optim.Optimizer,\n    device: str = \"cuda\"\n) -> float:\n    \n    for epoch in trange(epochs, desc=\"train epoch\"):    # \"trange\" adds a bar, \"desc\" adds a description\n        model.train()\n        train_loss_averager = make_averager()  # mantain a running average of the loss\n\n        # TRAIN\n        tqdm_iterator = tqdm(                      # adds a progress bar\n            enumerate(zip(train_dl,meta_train_dl)),\n            total=len(train_dl),\n            desc=f\"batch [loss: None]\",\n            leave=False,\n        )\n        for batch_idx, ((data,target), meta) in tqdm_iterator:\n            # send to device\n            meta = meta[0]\n            data, target, meta = data.to(device), target.to(device), meta.to(device)\n\n            opt.zero_grad()\n            output = model([data, meta])\n            loss = loss_func(output, target)\n            loss.backward()\n            opt.step()\n            \n            train_loss_averager(loss.item())\n            \n            tqdm_iterator.set_description(\n                f\"train batch [avg loss: {train_loss_averager(None):.3f}]\"\n            )\n            tqdm_iterator.refresh()\n        \n        scheduler.step()\n        # TEST\n        test_out = test_model(loss_func, test_dl, meta_test_dl, model,device)   # test_model outputs 'test_out' list\n\n        print(\n            f\"Epoch: {epoch}\\n\"\n            f\"Train set: Average loss: {train_loss_averager(None):.4f}\\n\"\n            f\"Val set: Average loss: {test_out['loss_averager'](None):.4f}, \"\n            f\"Accuracy: {test_out['correct']}/{VAL_TOT} \"\n            f\"({test_out['accuracy']:.1f}%)\\n\"\n        )\n        train_losses.append(train_loss_averager(None))\n        val_losses.append(test_out['loss_averager'](None))\n        accuracy.append(test_out['correct']/VAL_TOT)\n\n#     models_accuracy = test_out['accuracy']\n    return test_out['accuracy']      # final accuracy\n    \n# Just a function to count the number of parameters\ndef count_parameters(model: torch.nn.Module) -> int:\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T13:05:29.359078Z","iopub.execute_input":"2022-05-11T13:05:29.359682Z","iopub.status.idle":"2022-05-11T13:05:29.380144Z","shell.execute_reply.started":"2022-05-11T13:05:29.359629Z","shell.execute_reply":"2022-05-11T13:05:29.379520Z"},"trusted":true},"execution_count":338,"outputs":[]},{"cell_type":"code","source":"epochs = 35\nfit_model = 1\nmodel = resnet50\n\ntrain_losses, val_losses, accuracy = [], [], []\n# class_weights = 1 - species_good_cnt/len(dataset)\n# class_weights = torch.tensor(class_weights).to(torch.float32).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.75)  # decays lr of each par. group by gamma every step_size epochs\nloss_func = nn.CrossEntropyLoss()#weight = class_weights)\nprint(f'Number of parameters: {count_parameters(model)}')\ntqdm._instances.clear()\n\nif fit_model:\n    fit(loss_func = loss_func,\n    epochs=epochs, \n    train_dl=train_loader,\n    meta_train_dl = meta_train_loader,\n    test_dl=val_loader,\n    meta_test_dl = meta_val_loader,\n    model=model,\n    opt=optimizer,\n    device=device)\n    \n    fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n    axs[0].set_title('Losses')\n    axs[0].plot(train_losses, label='Train loss')\n    axs[0].plot(val_losses, label='Val loss')\n    axs[0].legend()\n    axs[1].plot(accuracy)\n    axs[1].set_title('Accuracy')\n    for ax in axs.flat:\n        ax.set(xlabel='Epochs')","metadata":{"execution":{"iopub.status.busy":"2022-05-11T13:05:33.196083Z","iopub.execute_input":"2022-05-11T13:05:33.196405Z","iopub.status.idle":"2022-05-11T13:06:13.747964Z","shell.execute_reply.started":"2022-05-11T13:05:33.196371Z","shell.execute_reply":"2022-05-11T13:06:13.745166Z"},"trusted":true},"execution_count":339,"outputs":[]},{"cell_type":"code","source":"save = 0\nfrom datetime import datetime\nimport pytz\nif save:\n    timezone = pytz.timezone('Europe/Rome')\n    now = datetime.now(tz = timezone)\n    time_info = now.strftime(\"%d-%m--%H-%M\")\n    model_name = 'Net50_meta128_more_timerec_t150_f5_GN0.25_drop2d0.3_35ep'+ '_' + time_info + '.pt'\n    model_path = os.path.join('./', model_name)   # ./model_name.pt\n    torch.save(model.state_dict(), model_path)\n\n# os.remove(os.path.join(output_dir, 'model_cnn_200'))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:27:45.927689Z","iopub.execute_input":"2022-05-11T11:27:45.928097Z","iopub.status.idle":"2022-05-11T11:27:45.941698Z","shell.execute_reply.started":"2022-05-11T11:27:45.928051Z","shell.execute_reply":"2022-05-11T11:27:45.940875Z"},"trusted":true},"execution_count":246,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.rmtree('./dataset')","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:27:45.943312Z","iopub.execute_input":"2022-05-11T11:27:45.943646Z","iopub.status.idle":"2022-05-11T11:27:52.680869Z","shell.execute_reply.started":"2022-05-11T11:27:45.943603Z","shell.execute_reply":"2022-05-11T11:27:52.679872Z"},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"markdown","source":"## Soundscapes","metadata":{}},{"cell_type":"code","source":"# model.load_state_dict(torch.load('../input/net50-meta128-masks-timerec-09051425/Net50_meta128_masks_timerec_09-05--14-25.pt',\n#                                 map_location=torch.device('cpu')))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:27:52.682306Z","iopub.execute_input":"2022-05-11T11:27:52.682607Z","iopub.status.idle":"2022-05-11T11:27:54.418459Z","shell.execute_reply.started":"2022-05-11T11:27:52.682567Z","shell.execute_reply":"2022-05-11T11:27:54.417493Z"},"trusted":true},"execution_count":248,"outputs":[]},{"cell_type":"code","source":"def get_TEST_landscape_spectrograms(audio_path, output_dir):\n    \n    sig, rate = librosa.load(audio_path, sr=SAMPLING_RATE, offset=None)\n    \n    lunp_samples = int(INPUT_LENGTH*SAMPLING_RATE)   # number of time samples in a 5s piece of signal (5s*32000Hz)\n    \n    # split signal into five second lumps\n    sig_splits = []\n    for i in range(0, len(sig), lunp_samples):\n        split = sig[i:i + lunp_samples]\n\n        # End of signal\n        if len(split) < lunp_samples:\n            break\n        sig_splits.append(split)\n    \n    # extract mel spectrograms\n    split_count = 0\n    samples = []\n    for lump in sig_splits:\n        \n        HOP_LENGTH = int((INPUT_LENGTH*SAMPLING_RATE)/(SPEC_SHAPE[1]-1))\n        mel_spec = librosa.feature.melspectrogram(y=lump,\n                                                 sr=SAMPLING_RATE,\n                                                 n_fft=1024,\n                                                 hop_length=HOP_LENGTH,\n                                                 n_mels=SPEC_SHAPE[0],\n                                                 fmin=FMIN,\n                                                 fmax=FMAX)\n        \n        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n    \n        # Normalize\n        mel_spec -= mel_spec.min()\n        mel_spec /= mel_spec.max()\n        \n        # Save as image file\n        # THIS TIME IN A SINGLE FOLDER (NO LABELS):\n        save_path = os.path.join(output_dir, audio_path.rsplit(os.sep, 1)[-1].rsplit('.', 1)[0].rsplit('_',1)[0] + \n                                 '_' + str((split_count+1)*5) + '.png')\n        \n        im = Image.fromarray(mel_spec * 255.0).convert(\"L\") # color -> greyscale (mode “L”): L = R * 299/1000 + G * 587/1000 + B * 114/1000\n        im.save(save_path)\n        \n        samples.append(save_path)\n        split_count += 1\n            \n    filename = audio_path.rsplit(os.sep, 1)[-1].rsplit('.', 1)[0]\n    location = filename.rsplit('_',2)[1]\n    meta_lat.append(geo_map[filename.rsplit('_',2)[1]][0])\n    meta_lon.append(geo_map[filename.rsplit('_',2)[1]][1])\n    date = filename.rsplit('_',1)[1][0:4] + '-' + filename.rsplit('_',1)[1][4:6] + '-' + filename.rsplit('_',1)[1][6:8]\n    meta_date.append(date_transform(date))\n    return samples","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:54:26.122904Z","iopub.execute_input":"2022-05-11T11:54:26.123212Z","iopub.status.idle":"2022-05-11T11:54:26.137153Z","shell.execute_reply.started":"2022-05-11T11:54:26.123174Z","shell.execute_reply":"2022-05-11T11:54:26.135901Z"},"trusted":true},"execution_count":281,"outputs":[]},{"cell_type":"code","source":"# EXTRACT TEST SPECTROGRAMS\n\nif not os.path.isdir('./TEST_SOUNDSCAPES_MEL_DATASET'):\n    !pip install natsort\n    import librosa\n    from natsort import natsorted\n\n    # os.rmdir('./TEST_SOUNDSCAPES_MEL_DATASET')\n\n    input_dir = '../input/birdclef-2021/train_soundscapes'\n    output_dir = './TEST_SOUNDSCAPES_MEL_DATASET'\n    os.makedirs(output_dir)\n    TEST_SPECS = []\n    geo_map = {'COL': [5.57,-75.85], 'COR':[10.12, -84.51], 'SNE':[38.49,-119.95], 'SSW':[42.47,-76.45]}\n    meta_lat = []\n    meta_lon = []\n    meta_date = []\n\n    # ORDER LIST OF FILENAMES according to train_soundscapes_labels.csv: COL-COR-SNE-SSW, ID NUMBER\n    filename_list = natsorted(os.listdir(input_dir))\n    COL_list = []\n    COR_list = []\n    SNE_list = []\n    SSW_list = []\n    for filename in filename_list:\n        if 'COL' in filename:\n            COL_list.append(filename)\n        if 'COR' in filename:\n            COR_list.append(filename)\n        if 'SNE' in filename:\n            SNE_list.append(filename)\n        if 'SSW' in filename:\n            SSW_list.append(filename)\n\n    ordered_list = COL_list + COR_list + SNE_list + SSW_list\n    # print(ordered_list)\n\n    for filename in ordered_list:\n        audio_file_path = os.path.join(input_dir, filename)\n        TEST_SPECS += get_TEST_landscape_spectrograms(audio_file_path, output_dir)\n\n    print('SUCCESSFULLY EXTRACTED {} SPECTROGRAMS'.format(len(TEST_SPECS)))  # 2400","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:54:29.788210Z","iopub.execute_input":"2022-05-11T11:54:29.788559Z","iopub.status.idle":"2022-05-11T11:55:15.984284Z","shell.execute_reply.started":"2022-05-11T11:54:29.788523Z","shell.execute_reply":"2022-05-11T11:55:15.983208Z"},"trusted":true},"execution_count":282,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree('./TEST_SOUNDSCAPES_MEL_DATASET')","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:55:15.987135Z","iopub.execute_input":"2022-05-11T11:55:15.987816Z","iopub.status.idle":"2022-05-11T11:55:15.994865Z","shell.execute_reply.started":"2022-05-11T11:55:15.987749Z","shell.execute_reply":"2022-05-11T11:55:15.993864Z"},"trusted":true},"execution_count":283,"outputs":[]},{"cell_type":"code","source":"image = Image.open('./TEST_SOUNDSCAPES_MEL_DATASET/11254_COR_5.png')\nimage","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:55:15.997382Z","iopub.execute_input":"2022-05-11T11:55:15.998119Z","iopub.status.idle":"2022-05-11T11:55:16.019770Z","shell.execute_reply.started":"2022-05-11T11:55:15.998053Z","shell.execute_reply":"2022-05-11T11:55:16.018478Z"},"trusted":true},"execution_count":284,"outputs":[]},{"cell_type":"code","source":"# META\nmeta_sound_df = pd.DataFrame(list(zip(meta_lat, meta_lon, meta_date)), columns =['latitude', 'longitude', 'date'])\nprint(meta_sound_df)\n\n# NORMALIZE \nfor idx, col in enumerate(['latitude', 'longitude', 'date']):\n    meta_sound_df[col] = ( meta_sound_df[col] - META_MEAN[idx] ) / META_STD[idx]\n\na = meta_sound_df.columns    \n# REPEAT: repeat each row in meta_sound_df 600s/5s times:\nmeta_sound_df = pd.DataFrame(np.repeat(meta_sound_df.values, 120, axis=0))\nmeta_sound_df.columns = a\nmeta_sound_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:55:16.027077Z","iopub.execute_input":"2022-05-11T11:55:16.030014Z","iopub.status.idle":"2022-05-11T11:55:16.067007Z","shell.execute_reply.started":"2022-05-11T11:55:16.029942Z","shell.execute_reply":"2022-05-11T11:55:16.065912Z"},"trusted":true},"execution_count":285,"outputs":[]},{"cell_type":"code","source":"meta_sound_tensor = torch.tensor([meta_sound_df['latitude'].values, meta_sound_df['longitude'].values, meta_sound_df['date'].values]).float()\nmeta_sound_tensor = torch.transpose(meta_sound_tensor, 0, 1)\n# meta_sound_tensor, meta_sound_tensor.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:55:16.072306Z","iopub.execute_input":"2022-05-11T11:55:16.074773Z","iopub.status.idle":"2022-05-11T11:55:16.094068Z","shell.execute_reply.started":"2022-05-11T11:55:16.074712Z","shell.execute_reply":"2022-05-11T11:55:16.092892Z"},"trusted":true},"execution_count":286,"outputs":[]},{"cell_type":"code","source":"transform_inference =  transforms.Compose([transforms.Grayscale(), \n                                           transforms.ToTensor(), \n                                           transforms.Normalize(mean=DATA_MEAN, std=DATA_STD)])\ndef image_loader(image_path):\n    \"\"\"load image, returns cuda tensor\"\"\"\n    image = Image.open(image_path)\n    image = transform_inference(image)\n    image = image.unsqueeze(0)  # adds dimension 0 of size 1 (batch dim) to obtain 1x1x48x128\n    if device.type == 'cuda':\n        return image.cuda()\n    else:\n        return image","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:55:16.099649Z","iopub.execute_input":"2022-05-11T11:55:16.099907Z","iopub.status.idle":"2022-05-11T11:55:16.105629Z","shell.execute_reply.started":"2022-05-11T11:55:16.099875Z","shell.execute_reply":"2022-05-11T11:55:16.104773Z"},"trusted":true},"execution_count":287,"outputs":[]},{"cell_type":"code","source":"# birds frequently mispredicted as nocalls:\n# birds_as_nocalls10 = list(['bkcchi', 'bobfly1', 'chswar', 'comyel', 'eastow', 'reevir1', 'rewbla', 'rucwar', 'sonspa'])\n\n# nocalls frequently mispredicted as birds:\n# nocalls_as_birds10 = list(['bcnher', 'bkcchi', 'carchi', 'grhowl', 'rewbla', 'whtspa'])     # too many grhowls ('great horned owl')!","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:27:54.522041Z","iopub.execute_input":"2022-05-11T11:27:54.522546Z","iopub.status.idle":"2022-05-11T11:27:54.533164Z","shell.execute_reply.started":"2022-05-11T11:27:54.522399Z","shell.execute_reply":"2022-05-11T11:27:54.532287Z"},"trusted":true},"execution_count":256,"outputs":[]},{"cell_type":"code","source":"# list in a dataframe pair of birds frequently heard together\nfrom itertools import combinations\ntruth = pd.read_csv('../input/birdclef-2021/train_soundscape_labels.csv')\n\ngroups = truth[truth['birds'].str.split().str.len() > 1]\ngroups['birds'] = groups['birds'].apply(lambda x: list(combinations(x.split(' '), 2)))\npairs = groups.explode('birds', ignore_index=True)\npairs_count = pd.DataFrame(np.stack(np.unique(pairs['birds'], return_counts = True), axis = 1),\n                                   columns = ['birds', 'occurrences'])\ncommon_pairs = pairs_count[pairs_count['occurrences']>10]\ncommon_pairs['birds'] = [' '.join(map(str, l)) for l in common_pairs['birds']]\ncommon_pairs = common_pairs.sort_values(by=['occurrences'], ascending=False)\ncommon_pairs","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:55:16.106937Z","iopub.execute_input":"2022-05-11T11:55:16.107901Z","iopub.status.idle":"2022-05-11T11:55:16.146583Z","shell.execute_reply.started":"2022-05-11T11:55:16.107857Z","shell.execute_reply":"2022-05-11T11:55:16.145781Z"},"trusted":true},"execution_count":288,"outputs":[]},{"cell_type":"code","source":"# Predict MULTILABEL\ntest_soundscapes_dir =  './TEST_SOUNDSCAPES_MEL_DATASET'\nfrom torch.nn import AvgPool2d\nfrom collections import deque\n\nCol_averager = AvgPool2d(kernel_size =(6,128*4))                     # 20 seconds\nPatch_averager = AvgPool2d(kernel_size =(6,4))\nlast_saved = 0         # saved last_birds number (between these, accept lower probabilities for species1)\nX = 10                  # number of highest score guesses to check for birds related to species1 (multilabel)\nmultilabel = False\n\n# Store the results\ndata = {'row_id': [], 'prediction': [], 'score': []}\nwith torch.no_grad():\n    cnt = 0\n    last_birds = deque(maxlen=last_saved)\n    for idx, spec_name in enumerate(os.listdir(test_soundscapes_dir)):\n        if idx % 120 == 0:                               # new 10 minutes audio (120*5s)\n            last_birds = deque(maxlen=last_saved)\n            print('audio n. ', int(idx/120))\n        path = os.path.join(test_soundscapes_dir, spec_name)\n        \n        spec = image_loader(path)\n        meta = meta_sound_tensor[idx].unsqueeze(0)\n        spec, meta = spec.to(device), meta.to(device)\n        model.eval()\n        \n        # repeat 2/4/6 times to reach 10/20/30 seconds\n        spec = torch.cat((spec, spec, spec, spec),-1)               # 20 seconds\n        prediction = nn.functional.softmax(model([spec, meta]))[0]\n        prediction = torch.Tensor.cpu(prediction)\n        \n        # store 1st, 2nd and first X guesses (the latter to be used in case of birds frequently heard together)\n        idx2,idx1 = np.argpartition(prediction, -2)[-2:]            # indices of the 2 highest scores (max on the right)\n        bestX_idx = np.argpartition(prediction, -X)[-X:]            # indices of the X highest scores\n        species1, species2 = all_species[idx1], all_species[idx2]\n        score1, score2 = prediction[idx1], prediction[idx2]         # 2 highest scores\n        bestX = list(all_species[bestX_idx])                        # X highest scores\n        bestX.remove(species1)                                      # (species1 removed)\n        \n        data['row_id'].append(spec_name.rsplit('.', 1)[0])\n        \n        # filter2: separate birdcalls | nocalls\n        AvgCol = Col_averager(spec)            # 1x1x8x1\n        AvgPatches = Patch_averager(spec)      # 1x1x8x128\n        diff = AvgPatches - AvgCol             # 1x1x8x128\n        diff = diff.view(diff.shape[0], -1)    # 1x(8*128)\n        birdcall = np.any(np.absolute(np.array(torch.Tensor.cpu(diff)))>0.63, axis=1)\n        \n        bird2_flag = 0\n        if birdcall and (species1 != 'grhowl') and (score1>0.28 or (last_birds.count(species1)>=3 and score1>0.15)):# or (species1 in birds_as_nocalls10 and score1>0.3):\n            last_birds.append(species1)\n            has_rel_birds = common_pairs['birds'].str.contains(species1)                   # if 'common_pairs' rows contain species1\n            if any(has_rel_birds):\n                rel_pairs = pd.DataFrame(common_pairs.loc[has_rel_birds])                  # rows containing species1\n                bestX_pattern = '|'.join(bestX)\n                rel_pairs['in_bestX'] = rel_pairs['birds'].str.contains(bestX_pattern)     # rows True if bird2 in row is in bestX\n                rel_pairs_in10 = rel_pairs.loc[rel_pairs['in_bestX']]['birds'].to_list()   # list of pairs with bird2 in bestX\n                if rel_pairs_in10:\n                    rel_bird = rel_pairs_in10[0].rsplit(' ')            # keep first pair, split it\n                    rel_bird.remove(species1)                           # bird related to species1\n                    rel_bird = str(rel_bird)\n                    bird2_flag = 1\n                    species2 = rel_bird\n            \n            if score1 < 0.35:     # add 'nocall' label anyway\n                if multilabel and bird2_flag:                            # multi-birds label is inaccurate\n                    data['prediction'].append({species1, species2, 'nocall'})\n                    cnt +=2\n                else:\n                    data['prediction'].append({species1, 'nocall'})\n                    cnt += 1\n            else:\n                if multilabel and bird2_flag:\n                    data['prediction'].append({species1, species2})\n                    cnt +=2\n                else:\n                    data['prediction'].append({species1})\n                    cnt += 1\n        else:\n            data['prediction'].append({'nocall'})\n        # Add the confidence score\n        data['score'].append( str(score1.item()) + ' ' + str(score2.item()) )\n\nprint('SOUNDSCAPE ANALYSIS DONE. FOUND {} BIRDS.'.format(cnt))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:59:51.831856Z","iopub.execute_input":"2022-05-11T11:59:51.832159Z","iopub.status.idle":"2022-05-11T12:02:23.134863Z","shell.execute_reply.started":"2022-05-11T11:59:51.832121Z","shell.execute_reply":"2022-05-11T12:02:23.134196Z"},"trusted":true},"execution_count":294,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame(data, columns = ['row_id', 'prediction', 'score'])       # new dataframe\nresults = pd.merge(truth, results, on='row_id')                                 # merge with true labels\n\n# Let's look at some entries\nresults[1050:1100]","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:02:23.136287Z","iopub.execute_input":"2022-05-11T12:02:23.136612Z","iopub.status.idle":"2022-05-11T12:02:23.173126Z","shell.execute_reply.started":"2022-05-11T12:02:23.136582Z","shell.execute_reply":"2022-05-11T12:02:23.172409Z"},"trusted":true},"execution_count":295,"outputs":[]},{"cell_type":"code","source":"all_species_nocall = np.append('nocall', all_species)\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer(classes = all_species_nocall)\n\ny_prediction = list(results['prediction'])\ny_pred_matrix = mlb.fit_transform(y_prediction)\n\n# true birds list to list of sets\ny_truth = []\nfor element in list(results['birds']):\n    y_truth.append(set(element.split()))\ny_true_matrix = mlb.fit_transform(y_truth)\n\nf1 = f1_score(y_true_matrix, y_pred_matrix, average='micro')\nprint('F1 = %.3f' %(f1))\n\nf1_398 = f1_score(y_true_matrix, y_pred_matrix, average=None)            # f1 for each class\nprint('\\n', 'F1_classes:\\n', f1_398)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T11:13:14.558244Z","iopub.execute_input":"2022-05-12T11:13:14.560790Z","iopub.status.idle":"2022-05-12T11:13:15.687390Z","shell.execute_reply.started":"2022-05-12T11:13:14.560698Z","shell.execute_reply":"2022-05-12T11:13:15.686117Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Predict ONELABEL\ntest_soundscapes_dir =  './TEST_SOUNDSCAPES_MEL_DATASET'\nfrom torch.nn import AvgPool2d\n\nCol_averager = AvgPool2d(kernel_size =(6,128*4))                     # 20 seconds\nPatch_averager1 = AvgPool2d(kernel_size =(6,4))\nPatch_averager2 = AvgPool2d(kernel_size =(8,7))\n\n# Store the results\ndata = {'row_id': [], 'prediction': [], 'score': []}\ndata_no_grhowl = {'row_id': [], 'prediction': [], 'score': []}\ndata_no_grhowl_thresh = {'row_id': [], 'prediction': [], 'score': []}\n\nwith torch.no_grad():\n    cnt1,cnt2,cnt3 = 0, 0, 0\n    for idx, spec_name in enumerate(os.listdir(test_soundscapes_dir)):\n        path = os.path.join(test_soundscapes_dir, spec_name)\n        \n        spec = image_loader(path)\n        meta = meta_sound_tensor[idx].unsqueeze(0)\n        spec, meta = spec.to(device), meta.to(device)\n        model.eval()\n        \n        # ripeto per 2/4/6 così raggiungo 10/20/30 secondi\n        spec = torch.cat((spec, spec, spec, spec),-1)                            # 20 seconds\n        prediction = nn.functional.softmax(model([spec, meta]))[0]\n        prediction = torch.Tensor.cpu(prediction)\n        idx = np.argmax(prediction)     # highest score index\n        species = all_species[idx]\n        score = prediction[idx]         # highest score\n\n        data['row_id'].append(spec_name.rsplit('.', 1)[0])\n        data_no_grhowl['row_id'].append(spec_name.rsplit('.', 1)[0])\n        data_no_grhowl_thresh['row_id'].append(spec_name.rsplit('.', 1)[0])\n        \n        AvgCol = Col_averager(spec)\n        AvgPatches = Patch_averager1(spec)\n        diff = AvgPatches - AvgCol\n        diff = diff.view(diff.shape[0], -1)\n        val = int(np.any(np.absolute(np.array(torch.Tensor.cpu(diff)))>0.63, axis=1))\n\n        #1\n        if val:\n            data['prediction'].append(species)\n            cnt1 += 1\n        else:\n            data['prediction'].append('nocall')\n        \n        #2\n        if val and species != 'grhowl':\n            data_no_grhowl['prediction'].append(species)\n            cnt2 += 1\n        else:\n            data_no_grhowl['prediction'].append('nocall')   \n        \n        #3\n        if val and species != 'grhowl' and score>0.28:\n            data_no_grhowl_thresh['prediction'].append(species)\n            cnt3 += 1\n        else:\n            data_no_grhowl_thresh['prediction'].append('nocall')   \n        \n        # Add the confidence score\n        data['score'].append(score.item())\n        data_no_grhowl['score'].append(score.item())\n        data_no_grhowl_thresh['score'].append(score.item())\n\nprint('SOUNDSCAPE ANALYSIS DONE. FOUND {0}, {1}, {2} BIRDS.'.format(cnt1, cnt2, cnt3))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:36:09.456691Z","iopub.execute_input":"2022-05-11T12:36:09.457502Z","iopub.status.idle":"2022-05-11T12:38:51.391076Z","shell.execute_reply.started":"2022-05-11T12:36:09.457454Z","shell.execute_reply":"2022-05-11T12:38:51.390073Z"},"trusted":true},"execution_count":306,"outputs":[]},{"cell_type":"code","source":"# data\nresults = pd.DataFrame(data, columns = ['row_id', 'prediction', 'score'])       # new dataframe\nresults = pd.merge(truth, results, on='row_id')                                 # merge with true labels\n\nonly_birds = results.loc[results['birds'] != 'nocall']           # dataframe: only rows with truth != 'nocall'\nn_birds = only_birds.shape[0]                                    # rows with truth != 'nocall': shape= (871, 7)\nn_nocalls = results.loc[results['birds'] == 'nocall'].shape[0]   # rows with truth == 'nocall': shape= (1529, 7) (63%)\n\ncorrect_birds = sum([x[0] in x[1] for x in zip(only_birds['prediction'], only_birds['birds'])])                  # birds correctly predicted\ncorrect_nocalls = results.loc[results['birds'] == 'nocall'][results['birds'] == results['prediction']].shape[0]  # nocall correctly predicted\nbirds_as_birds = only_birds[results['prediction'] != 'nocall'].shape[0]                                          # birds predicted as birds:\n\nprint('Correct birds:', correct_birds, '(%.3f %%)' %((correct_birds/n_birds)*100))\nprint('Birds predicted as birds:', birds_as_birds, '(%.3f %%)' %((birds_as_birds/n_birds)*100))\nprint('Correct nocalls:', correct_nocalls, '(%.3f %%)' %((correct_nocalls/n_nocalls)*100))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:38:51.393246Z","iopub.execute_input":"2022-05-11T12:38:51.393758Z","iopub.status.idle":"2022-05-11T12:38:51.420954Z","shell.execute_reply.started":"2022-05-11T12:38:51.393708Z","shell.execute_reply":"2022-05-11T12:38:51.419759Z"},"trusted":true},"execution_count":307,"outputs":[]},{"cell_type":"code","source":"# data, no 'grhowl' label  -> 3% of birds predicted as birds are grhowl, but they were misclassified\nresults = pd.DataFrame(data_no_grhowl, columns = ['row_id', 'prediction', 'score'])    # new dataframe\nresults = pd.merge(truth, results, on='row_id')                                        # merge with true labels\n\nonly_birds = results.loc[results['birds'] != 'nocall']           # dataframe: only rows with truth != 'nocall'\n\ncorrect_birds = sum([x[0] in x[1] for x in zip(only_birds['prediction'], only_birds['birds'])])                  # birds correctly predicted\ncorrect_nocalls = results.loc[results['birds'] == 'nocall'][results['birds'] == results['prediction']].shape[0]  # nocall correctly predicted\nbirds_as_birds = only_birds[results['prediction'] != 'nocall'].shape[0]                                          # birds predicted as birds:\n\nprint('Correct birds:', correct_birds, '(%.3f %%)' %((correct_birds/n_birds)*100))\nprint('Birds predicted as birds:', birds_as_birds, '(%.3f %%)' %((birds_as_birds/n_birds)*100))\nprint('Correct nocalls:', correct_nocalls, '(%.3f %%)' %((correct_nocalls/n_nocalls)*100))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:38:51.422742Z","iopub.execute_input":"2022-05-11T12:38:51.423411Z","iopub.status.idle":"2022-05-11T12:38:51.448926Z","shell.execute_reply.started":"2022-05-11T12:38:51.423358Z","shell.execute_reply":"2022-05-11T12:38:51.447910Z"},"trusted":true},"execution_count":308,"outputs":[]},{"cell_type":"code","source":"# data, no 'grhowl' label, score threshold  -> 21% of birds predicted as birds have score<0.28, but they provided only 1% of correct birds\nresults = pd.DataFrame(data_no_grhowl_thresh, columns = ['row_id', 'prediction', 'score'])   # dataframe\nresults = pd.merge(truth, results, on='row_id')                                              # merge with true labels\n\nonly_birds = results.loc[results['birds'] != 'nocall']           # dataframe: only rows with truth != 'nocall'\n\ncorrect_birds = sum([x[0] in x[1] for x in zip(only_birds['prediction'], only_birds['birds'])])                  # birds correctly predicted\ncorrect_nocalls = results.loc[results['birds'] == 'nocall'][results['birds'] == results['prediction']].shape[0]  # nocall correctly predicted\nbirds_as_birds = only_birds[results['prediction'] != 'nocall'].shape[0]                                          # birds predicted as birds:\n\nprint('Correct birds:', correct_birds, '(%.3f %%)' %((correct_birds/n_birds)*100))\nprint('Birds predicted as birds:', birds_as_birds, '(%.3f %%)' %((birds_as_birds/n_birds)*100))\nprint('Correct nocalls:', correct_nocalls, '(%.3f %%)' %((correct_nocalls/n_nocalls)*100))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:38:51.451082Z","iopub.execute_input":"2022-05-11T12:38:51.451330Z","iopub.status.idle":"2022-05-11T12:38:51.476685Z","shell.execute_reply.started":"2022-05-11T12:38:51.451299Z","shell.execute_reply":"2022-05-11T12:38:51.475685Z"},"trusted":true},"execution_count":309,"outputs":[]},{"cell_type":"code","source":"# birds predicted as nocalls\nbirds_as_nocalls = only_birds[results['prediction'] == 'nocall']\n# divide group of birds to get total number of occurrence per bird\nbirds_as_nocalls_SPLIT = birds_as_nocalls.assign(birds=birds_as_nocalls['birds'].str.split(' ')).explode('birds')\n# create dataframe with number of occurrences\nbirds_as_nocalls_df = pd.DataFrame(np.stack(np.unique(birds_as_nocalls_SPLIT['birds'], return_counts = True), axis = 1),\n                                   columns = ['birds', 'number'])\nmost_freq_mispredicted_birds = birds_as_nocalls_df.loc[birds_as_nocalls_df['number'] > 10].sort_values('number', ascending = False)\nmost_freq_mispredicted_birds","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:45:38.838487Z","iopub.execute_input":"2022-05-11T11:45:38.838949Z","iopub.status.idle":"2022-05-11T11:45:38.862036Z","shell.execute_reply.started":"2022-05-11T11:45:38.838892Z","shell.execute_reply":"2022-05-11T11:45:38.861165Z"},"trusted":true},"execution_count":270,"outputs":[]},{"cell_type":"code","source":"# nocalls predicted as birds\nnocalls_as_birds = only_nocalls[results['prediction'] != 'nocall']\n# create dataframe with number of occurrences\nnocalls_as_birds_df = pd.DataFrame(np.stack(np.unique(nocalls_as_birds['prediction'], return_counts = True), axis = 1),\n                                   columns = ['birds', 'number'])\nmost_freq_mispredicted_nocalls = nocalls_as_birds_df.loc[nocalls_as_birds_df['number'] > 10]\nmost_freq_mispredicted_nocalls","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:45:38.863409Z","iopub.execute_input":"2022-05-11T11:45:38.863914Z","iopub.status.idle":"2022-05-11T11:45:38.878801Z","shell.execute_reply.started":"2022-05-11T11:45:38.863870Z","shell.execute_reply":"2022-05-11T11:45:38.877886Z"},"trusted":true},"execution_count":271,"outputs":[]},{"cell_type":"code","source":"# onelabel accuracy (no additional 'nocall' label if score<0.35)\n# with last results = pd.DataFrame(data_no_grhowl_thresh, ...) :\nf1 = f1_score(results['prediction'], results['birds'], average = 'micro')\naccuracy = sum([x[0] in x[1] for x in zip(results['prediction'], results['birds'])])/2400\nprint('Accuracy = %.1f %%' %(accuracy*100))\nprint('F1 = %.5f' %(f1))\n\n# Test accuracy (on train_soundscapes) of a fake model classifying all as 'nocall' is 63.7%!!!","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:56:53.831969Z","iopub.execute_input":"2022-05-11T12:56:53.832350Z","iopub.status.idle":"2022-05-11T12:56:53.857857Z","shell.execute_reply.started":"2022-05-11T12:56:53.832309Z","shell.execute_reply":"2022-05-11T12:56:53.856623Z"},"trusted":true},"execution_count":310,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.rmtree('./TEST_SOUNDSCAPES_MEL_DATASET')","metadata":{"execution":{"iopub.status.busy":"2022-05-11T11:45:38.895481Z","iopub.execute_input":"2022-05-11T11:45:38.896121Z","iopub.status.idle":"2022-05-11T11:45:38.990461Z","shell.execute_reply.started":"2022-05-11T11:45:38.896075Z","shell.execute_reply":"2022-05-11T11:45:38.989799Z"},"trusted":true},"execution_count":273,"outputs":[]}]}